#!/usr/bin/env python3
"""
éŸ©è¯­å”¤é†’è¯"í•˜ì´ë„›ì§€"è®­ç»ƒè„šæœ¬
ä½¿ç”¨OpenWakeWordæ¡†æ¶è®­ç»ƒè‡ªå®šä¹‰éŸ©è¯­å”¤é†’è¯æ¨¡å‹

ä½¿ç”¨æ–¹æ³•:
    python scripts/train_korean_wake_word.py --data_dir training_data --output_dir models

ä¾èµ–å®‰è£…:
    pip install openwakeword tensorflow librosa soundfile numpy
"""

import os
import sys
import argparse
import logging
from pathlib import Path
import numpy as np
import soundfile as sf
import librosa
from typing import List, Tuple

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class KoreanWakeWordTrainer:
    """éŸ©è¯­å”¤é†’è¯è®­ç»ƒå™¨"""
    
    def __init__(self, data_dir: str, output_dir: str):
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.wake_word = "í•˜ì´ë„›ì§€"
        self.romanized = "hi_nutji"
        
        # éŸ³é¢‘å‚æ•°
        self.sample_rate = 16000
        self.duration = 1.0  # 1ç§’éŸ³é¢‘ç‰‡æ®µ
        self.n_mels = 32
        self.n_fft = 512
        self.hop_length = 160
        
        # è®­ç»ƒå‚æ•°
        self.batch_size = 32
        self.epochs = 100
        self.learning_rate = 0.001
        
    def setup_directories(self):
        """è®¾ç½®è®­ç»ƒç›®å½•ç»“æ„"""
        directories = [
            self.data_dir / "positive",
            self.data_dir / "negative", 
            self.output_dir,
            self.output_dir / "logs",
            self.output_dir / "checkpoints"
        ]
        
        for dir_path in directories:
            dir_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"Created directory: {dir_path}")
    
    def collect_sample_instructions(self):
        """æ‰“å°æ ·æœ¬æ”¶é›†æŒ‡å¯¼"""
        print("\n" + "="*60)
        print("ğŸ¤ éŸ©è¯­å”¤é†’è¯è®­ç»ƒæ•°æ®æ”¶é›†æŒ‡å—")
        print("="*60)
        print(f"ç›®æ ‡å”¤é†’è¯: {self.wake_word} ({self.romanized})")
        print("\nğŸ“ ç›®å½•ç»“æ„:")
        print(f"  {self.data_dir}/")
        print(f"  â”œâ”€â”€ positive/  # æ­£æ ·æœ¬: è¯´'{self.wake_word}'çš„å½•éŸ³")
        print(f"  â””â”€â”€ negative/  # è´Ÿæ ·æœ¬: å…¶ä»–å£°éŸ³å’Œè¯æ±‡")
        
        print("\nâœ… æ­£æ ·æœ¬æ”¶é›†å»ºè®®:")
        print("  â€¢ å½•åˆ¶100-200ä¸ªä¸åŒçš„'í•˜ì´ë„›ì§€'å‘éŸ³")
        print("  â€¢ åŒ…å«ä¸åŒæ€§åˆ«ã€å¹´é¾„çš„è¯´è¯è€…")
        print("  â€¢ ä¸åŒè¯­è°ƒã€è¯­é€Ÿå’ŒéŸ³é‡")
        print("  â€¢ ä¸åŒç¯å¢ƒå™ªéŸ³æ¡ä»¶")
        print("  â€¢ æ ¼å¼: 16kHz, 16-bit, mono WAV")
        print("  â€¢ é•¿åº¦: 1-3ç§’")
        
        print("\nâŒ è´Ÿæ ·æœ¬æ”¶é›†å»ºè®®:")
        print("  â€¢ å…¶ä»–éŸ©è¯­è¯æ±‡å’Œå¥å­")
        print("  â€¢ ç¯å¢ƒå™ªéŸ³ã€éŸ³ä¹ã€ç”µè§†å£°éŸ³")
        print("  â€¢ ç±»ä¼¼å‘éŸ³çš„è¯æ±‡")
        print("  â€¢ è‹±è¯­å’Œå…¶ä»–è¯­è¨€")
        print("  â€¢ æ•°é‡åº”ä¸ºæ­£æ ·æœ¬çš„2-3å€")
        
        print("\nğŸ¯ å½•éŸ³è´¨é‡è¦æ±‚:")
        print("  â€¢ æ¸…æ™°çš„è¯­éŸ³ä¿¡å·")
        print("  â€¢ æœ€å°èƒŒæ™¯å™ªéŸ³")
        print("  â€¢ ä¸€è‡´çš„éŸ³é‡æ°´å¹³")
        print("  â€¢ é¿å…å›å£°å’Œå¤±çœŸ")
        
        print("\nğŸ“ æ–‡ä»¶å‘½åå»ºè®®:")
        print("  positive/speaker1_01.wav")
        print("  positive/speaker1_02.wav") 
        print("  positive/speaker2_01.wav")
        print("  negative/noise_01.wav")
        print("  negative/korean_word_01.wav")
        print("="*60)
    
    def validate_audio_files(self) -> Tuple[List[str], List[str]]:
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶"""
        positive_files = []
        negative_files = []
        
        # æ£€æŸ¥æ­£æ ·æœ¬
        positive_dir = self.data_dir / "positive"
        if positive_dir.exists():
            for file_path in positive_dir.glob("*.wav"):
                try:
                    data, sr = sf.read(file_path)
                    if sr != self.sample_rate:
                        logger.warning(f"Sample rate mismatch in {file_path}: {sr} != {self.sample_rate}")
                    positive_files.append(str(file_path))
                except Exception as e:
                    logger.error(f"Error reading {file_path}: {e}")
        
        # æ£€æŸ¥è´Ÿæ ·æœ¬
        negative_dir = self.data_dir / "negative"
        if negative_dir.exists():
            for file_path in negative_dir.glob("*.wav"):
                try:
                    data, sr = sf.read(file_path)
                    if sr != self.sample_rate:
                        logger.warning(f"Sample rate mismatch in {file_path}: {sr} != {self.sample_rate}")
                    negative_files.append(str(file_path))
                except Exception as e:
                    logger.error(f"Error reading {file_path}: {e}")
        
        logger.info(f"Found {len(positive_files)} positive samples")
        logger.info(f"Found {len(negative_files)} negative samples")
        
        return positive_files, negative_files
    
    def extract_features(self, audio_files: List[str]) -> np.ndarray:
        """æå–éŸ³é¢‘ç‰¹å¾"""
        features = []
        
        for file_path in audio_files:
            try:
                # åŠ è½½éŸ³é¢‘
                data, sr = librosa.load(file_path, sr=self.sample_rate)
                
                # ç¡®ä¿éŸ³é¢‘é•¿åº¦
                target_length = int(self.sample_rate * self.duration)
                if len(data) < target_length:
                    # å¡«å……é›¶
                    data = np.pad(data, (0, target_length - len(data)))
                else:
                    # æˆªå–
                    data = data[:target_length]
                
                # æå–æ¢…å°”é¢‘è°±å›¾
                mel_spec = librosa.feature.melspectrogram(
                    y=data,
                    sr=sr,
                    n_mels=self.n_mels,
                    n_fft=self.n_fft,
                    hop_length=self.hop_length
                )
                
                # è½¬æ¢ä¸ºå¯¹æ•°åˆ»åº¦
                log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
                
                features.append(log_mel_spec.T)  # è½¬ç½®ä»¥åŒ¹é…æ—¶é—´xç‰¹å¾æ ¼å¼
                
            except Exception as e:
                logger.error(f"Error processing {file_path}: {e}")
        
        return np.array(features)
    
    def create_tensorflow_model(self, input_shape: Tuple[int, int]):
        """åˆ›å»ºTensorFlowæ¨¡å‹"""
        try:
            import tensorflow as tf
            from tensorflow.keras import layers, models
        except ImportError:
            logger.error("TensorFlow not installed. Please install: pip install tensorflow")
            return None
        
        model = models.Sequential([
            layers.Input(shape=input_shape),
            
            # å·ç§¯å±‚
            layers.Conv1D(64, 3, activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling1D(2),
            layers.Dropout(0.3),
            
            layers.Conv1D(128, 3, activation='relu'),
            layers.BatchNormalization(),
            layers.MaxPooling1D(2),
            layers.Dropout(0.3),
            
            layers.Conv1D(256, 3, activation='relu'),
            layers.BatchNormalization(),
            layers.GlobalAveragePooling1D(),
            layers.Dropout(0.5),
            
            # å…¨è¿æ¥å±‚
            layers.Dense(128, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.3),
            
            # è¾“å‡ºå±‚
            layers.Dense(1, activation='sigmoid')
        ])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate),
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        return model
    
    def train_model(self):
        """è®­ç»ƒæ¨¡å‹"""
        try:
            import tensorflow as tf
        except ImportError:
            logger.error("TensorFlow not installed. Please install: pip install tensorflow")
            return False
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        positive_files, negative_files = self.validate_audio_files()
        
        if len(positive_files) < 10:
            logger.error(f"Not enough positive samples: {len(positive_files)}. Need at least 10.")
            return False
        
        if len(negative_files) < 20:
            logger.error(f"Not enough negative samples: {len(negative_files)}. Need at least 20.")
            return False
        
        # æå–ç‰¹å¾
        logger.info("Extracting features from positive samples...")
        positive_features = self.extract_features(positive_files)
        
        logger.info("Extracting features from negative samples...")
        negative_features = self.extract_features(negative_files)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X = np.concatenate([positive_features, negative_features])
        y = np.concatenate([
            np.ones(len(positive_features)),
            np.zeros(len(negative_features))
        ])
        
        # æ‰“ä¹±æ•°æ®
        indices = np.random.permutation(len(X))
        X = X[indices]
        y = y[indices]
        
        logger.info(f"Training data shape: {X.shape}")
        logger.info(f"Labels shape: {y.shape}")
        
        # åˆ›å»ºæ¨¡å‹
        model = self.create_tensorflow_model(X.shape[1:])
        if model is None:
            return False
        
        # è®¾ç½®å›è°ƒ
        callbacks = [
            tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True
            ),
            tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7
            ),
            tf.keras.callbacks.ModelCheckpoint(
                filepath=str(self.output_dir / "checkpoints" / "best_model.h5"),
                monitor='val_accuracy',
                save_best_only=True
            )
        ]
        
        # è®­ç»ƒæ¨¡å‹
        logger.info("Starting model training...")
        history = model.fit(
            X, y,
            batch_size=self.batch_size,
            epochs=self.epochs,
            validation_split=0.2,
            callbacks=callbacks,
            verbose=1
        )
        
        # ä¿å­˜æ¨¡å‹
        model_path = self.output_dir / f"{self.romanized}_korean.h5"
        model.save(str(model_path))
        logger.info(f"Model saved to: {model_path}")
        
        # è½¬æ¢ä¸ºTensorFlow Lite
        tflite_path = self.convert_to_tflite(model)
        if tflite_path:
            logger.info(f"TensorFlow Lite model saved to: {tflite_path}")
        
        return True
    
    def convert_to_tflite(self, model):
        """è½¬æ¢ä¸ºTensorFlow Liteæ ¼å¼"""
        try:
            import tensorflow as tf
            
            # è½¬æ¢ä¸ºTensorFlow Lite
            converter = tf.lite.TFLiteConverter.from_keras_model(model)
            converter.optimizations = [tf.lite.Optimize.DEFAULT]
            
            # é‡åŒ–ä»¥å‡å°‘æ¨¡å‹å¤§å°
            converter.representative_dataset = self.representative_dataset_gen
            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
            converter.inference_input_type = tf.int8
            converter.inference_output_type = tf.int8
            
            tflite_model = converter.convert()
            
            # ä¿å­˜TensorFlow Liteæ¨¡å‹
            tflite_path = self.output_dir / f"{self.romanized}_korean.tflite"
            with open(tflite_path, 'wb') as f:
                f.write(tflite_model)
            
            return tflite_path
            
        except Exception as e:
            logger.error(f"Error converting to TensorFlow Lite: {e}")
            return None
    
    def representative_dataset_gen(self):
        """ä»£è¡¨æ€§æ•°æ®é›†ç”Ÿæˆå™¨ç”¨äºé‡åŒ–"""
        positive_files, _ = self.validate_audio_files()
        sample_files = positive_files[:10]  # ä½¿ç”¨å‰10ä¸ªæ ·æœ¬
        
        for file_path in sample_files:
            features = self.extract_features([file_path])
            yield [features.astype(np.float32)]
    
    def test_model(self, model_path: str):
        """æµ‹è¯•æ¨¡å‹æ€§èƒ½"""
        try:
            import tensorflow as tf
            
            # åŠ è½½æ¨¡å‹
            if model_path.endswith('.tflite'):
                interpreter = tf.lite.Interpreter(model_path=model_path)
                interpreter.allocate_tensors()
                
                input_details = interpreter.get_input_details()
                output_details = interpreter.get_output_details()
                
                logger.info("TensorFlow Lite model loaded successfully")
                logger.info(f"Input shape: {input_details[0]['shape']}")
                logger.info(f"Output shape: {output_details[0]['shape']}")
                
            else:
                model = tf.keras.models.load_model(model_path)
                logger.info("Keras model loaded successfully")
                logger.info(f"Model summary:\n{model.summary()}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error testing model: {e}")
            return False

def main():
    parser = argparse.ArgumentParser(description="Train Korean wake word model")
    parser.add_argument("--data_dir", default="training_data/korean_wake_word", 
                       help="Directory containing training data")
    parser.add_argument("--output_dir", default="models/korean_wake_word",
                       help="Output directory for trained model")
    parser.add_argument("--collect_guide", action="store_true",
                       help="Show data collection guide")
    parser.add_argument("--train", action="store_true",
                       help="Start training")
    parser.add_argument("--test", type=str,
                       help="Test model file")
    
    args = parser.parse_args()
    
    trainer = KoreanWakeWordTrainer(args.data_dir, args.output_dir)
    trainer.setup_directories()
    
    if args.collect_guide:
        trainer.collect_sample_instructions()
    
    if args.train:
        success = trainer.train_model()
        if success:
            print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
            print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨: {args.output_dir}")
            print("ğŸ“± å°† .tflite æ–‡ä»¶å¤åˆ¶åˆ° app/src/main/assets/models/openWakeWord/")
        else:
            print("\nâŒ è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œä¾èµ–")
    
    if args.test:
        trainer.test_model(args.test)
    
    if not any([args.collect_guide, args.train, args.test]):
        print("ä½¿ç”¨ --help æŸ¥çœ‹å¯ç”¨é€‰é¡¹")
        trainer.collect_sample_instructions()

if __name__ == "__main__":
    main()
