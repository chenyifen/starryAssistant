#!/usr/bin/env python3
"""
éŸ©è¯­å”¤é†’è¯è®­ç»ƒæ•°æ®æ”¶é›†å·¥å…·
æ”¯æŒå¤šç§æ•°æ®æºï¼šTTSåˆæˆã€åœ¨çº¿æœåŠ¡ã€å½•éŸ³å·¥å…·

ä½¿ç”¨æ–¹æ³•:
    python scripts/collect_korean_training_data.py --method tts --output_dir training_data
    python scripts/collect_korean_training_data.py --method record --output_dir training_data
    python scripts/collect_korean_training_data.py --method download --output_dir training_data
"""

import os
import sys
import argparse
import logging
from pathlib import Path
import requests
import json
import time
import random
from typing import List, Dict, Tuple
import subprocess

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class KoreanDataCollector:
    """éŸ©è¯­è®­ç»ƒæ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, output_dir: str):
        self.output_dir = Path(output_dir)
        self.wake_word = "í•˜ì´ë„›ì§€"
        self.romanized = "hi_nutji"
        
        # åˆ›å»ºç›®å½•ç»“æ„
        self.positive_dir = self.output_dir / "positive"
        self.negative_dir = self.output_dir / "negative"
        self.temp_dir = self.output_dir / "temp"
        
        for dir_path in [self.positive_dir, self.negative_dir, self.temp_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
    
    def show_collection_guide(self):
        """æ˜¾ç¤ºæ•°æ®æ”¶é›†å®Œæ•´æŒ‡å—"""
        print("\n" + "="*80)
        print("ğŸ¤ éŸ©è¯­å”¤é†’è¯'í•˜ì´ë„›ì§€'è®­ç»ƒæ•°æ®æ”¶é›†å®Œæ•´æŒ‡å—")
        print("="*80)
        
        print("\nğŸ“‹ æ”¶é›†æ–¹æ³•æ¦‚è§ˆ:")
        print("1. ğŸ¤– TTSåˆæˆ - ä½¿ç”¨åœ¨çº¿TTSæœåŠ¡ç”ŸæˆåŸºç¡€æ•°æ®")
        print("2. ğŸ™ï¸ çœŸäººå½•éŸ³ - æ”¶é›†çœŸå®è¯­éŸ³æ•°æ®")
        print("3. ğŸ“¥ åœ¨çº¿ä¸‹è½½ - ä»å…¬å¼€æ•°æ®é›†ä¸‹è½½")
        print("4. ğŸ”„ æ•°æ®å¢å¼º - å¯¹ç°æœ‰æ•°æ®è¿›è¡Œå˜æ¢")
        
        print("\n" + "="*50)
        print("æ–¹æ³•1: ğŸ¤– åœ¨çº¿TTSæœåŠ¡ç”Ÿæˆ")
        print("="*50)
        
        print("\nğŸŒ æ¨èçš„å…è´¹TTSæœåŠ¡:")
        print("â€¢ Google Text-to-Speech (gTTS)")
        print("â€¢ Microsoft Azure Cognitive Services (å…è´¹é¢åº¦)")
        print("â€¢ Amazon Polly (å…è´¹é¢åº¦)")
        print("â€¢ Naver Clova Voice (éŸ©è¯­ä¸“ç”¨)")
        print("â€¢ Kakao i Voice (éŸ©è¯­ä¸“ç”¨)")
        
        print("\nğŸ“ TTSç”Ÿæˆæ­¥éª¤:")
        print("1. æ³¨å†ŒTTSæœåŠ¡è´¦å·")
        print("2. è·å–APIå¯†é’¥")
        print("3. ä½¿ç”¨ä¸åŒå£°éŸ³ç”Ÿæˆ'í•˜ì´ë„›ì§€'")
        print("4. è°ƒæ•´è¯­é€Ÿã€éŸ³è°ƒã€éŸ³é‡")
        print("5. ç”Ÿæˆ50-100ä¸ªå˜ä½“")
        
        print("\nğŸ’» ä»£ç ç¤ºä¾‹ (Google TTS):")
        print("""
# å®‰è£…ä¾èµ–
pip install gtts pydub

# Pythonä»£ç 
from gtts import gTTS
from pydub import AudioSegment
import io

def generate_wake_word_variants():
    text = "í•˜ì´ë„›ì§€"
    
    # ä¸åŒè¯­è¨€ä»£ç å°è¯•
    lang_variants = ['ko', 'ko-KR']
    
    for i, lang in enumerate(lang_variants):
        for speed in [0.8, 1.0, 1.2]:  # ä¸åŒè¯­é€Ÿ
            tts = gTTS(text=text, lang=lang, slow=(speed < 1.0))
            
            # ä¿å­˜åˆ°å†…å­˜
            mp3_fp = io.BytesIO()
            tts.write_to_fp(mp3_fp)
            mp3_fp.seek(0)
            
            # è½¬æ¢ä¸ºWAV
            audio = AudioSegment.from_mp3(mp3_fp)
            audio = audio.set_frame_rate(16000).set_channels(1)
            
            # è°ƒæ•´éŸ³é‡
            audio = audio + random.randint(-5, 5)  # éšæœºéŸ³é‡è°ƒæ•´
            
            filename = f"tts_{lang}_{speed}_{i:03d}.wav"
            audio.export(f"positive/{filename}", format="wav")
        """)
        
        print("\n" + "="*50)
        print("æ–¹æ³•2: ğŸ™ï¸ çœŸäººå½•éŸ³æ”¶é›†")
        print("="*50)
        
        print("\nğŸ¯ å½•éŸ³è¦æ±‚:")
        print("â€¢ æ ¼å¼: 16kHz, 16-bit, mono WAV")
        print("â€¢ é•¿åº¦: 1-3ç§’")
        print("â€¢ ç¯å¢ƒ: å®‰é™ï¼Œæ— å›å£°")
        print("â€¢ è®¾å¤‡: è´¨é‡å¥½çš„éº¦å…‹é£")
        
        print("\nğŸ‘¥ å½•éŸ³ç­–ç•¥:")
        print("â€¢ ç”·æ€§å£°éŸ³: 30-40ä¸ªæ ·æœ¬")
        print("â€¢ å¥³æ€§å£°éŸ³: 30-40ä¸ªæ ·æœ¬")
        print("â€¢ å„¿ç«¥å£°éŸ³: 20-30ä¸ªæ ·æœ¬")
        print("â€¢ è€å¹´äººå£°éŸ³: 10-20ä¸ªæ ·æœ¬")
        
        print("\nğŸµ è¯­éŸ³å˜åŒ–:")
        print("â€¢ æ­£å¸¸è¯­è°ƒ")
        print("â€¢ ç–‘é—®è¯­è°ƒ")
        print("â€¢ å‘½ä»¤è¯­è°ƒ")
        print("â€¢ è½»å£°ç»†è¯­")
        print("â€¢ å¤§å£°å‘¼å«")
        
        print("\nğŸ› ï¸ æ¨èå½•éŸ³å·¥å…·:")
        print("â€¢ Audacity (å…è´¹ï¼Œè·¨å¹³å°)")
        print("â€¢ GarageBand (Mac)")
        print("â€¢ Voice Recorder (æ‰‹æœº)")
        print("â€¢ OBS Studio (é«˜çº§)")
        
        print("\nğŸ“± æ‰‹æœºå½•éŸ³è„šæœ¬:")
        print("""
# ä½¿ç”¨æ‰‹æœºå½•éŸ³çš„æ‰¹é‡å¤„ç†
# 1. å½•åˆ¶å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
# 2. ä¼ è¾“åˆ°ç”µè„‘
# 3. æ‰¹é‡è½¬æ¢æ ¼å¼

# FFmpegæ‰¹é‡è½¬æ¢
for file in *.m4a; do
    ffmpeg -i "$file" -ar 16000 -ac 1 -sample_fmt s16 "${file%.*}.wav"
done
        """)
        
        print("\n" + "="*50)
        print("æ–¹æ³•3: ğŸ“¥ å…¬å¼€æ•°æ®é›†ä¸‹è½½")
        print("="*50)
        
        print("\nğŸ—ƒï¸ éŸ©è¯­è¯­éŸ³æ•°æ®é›†:")
        print("â€¢ KSS Dataset (Korean Single Speaker)")
        print("â€¢ Zeroth-Korean (Mozilla Common Voice)")
        print("â€¢ AIHub í•œêµ­ì–´ ìŒì„± ë°ì´í„°")
        print("â€¢ Google Speech Commands (éƒ¨åˆ†éŸ©è¯­)")
        
        print("\nğŸ” æ•°æ®é›†æœç´¢å…³é”®è¯:")
        print("â€¢ Korean speech dataset")
        print("â€¢ í•œêµ­ì–´ ìŒì„± ë°ì´í„°ì…‹")
        print("â€¢ Korean wake word dataset")
        print("â€¢ Korean voice commands")
        
        print("\n" + "="*50)
        print("æ–¹æ³•4: ğŸ”„ æ•°æ®å¢å¼ºæŠ€æœ¯")
        print("="*50)
        
        print("\nğŸ›ï¸ éŸ³é¢‘å¢å¼ºæ–¹æ³•:")
        print("â€¢ æ·»åŠ èƒŒæ™¯å™ªéŸ³")
        print("â€¢ è°ƒæ•´éŸ³é‡å’ŒéŸ³è°ƒ")
        print("â€¢ æ—¶é—´æ‹‰ä¼¸/å‹ç¼©")
        print("â€¢ æ·»åŠ å›å£°å’Œæ··å“")
        print("â€¢ é¢‘è°±é®è”½")
        
        print("\nğŸ’» æ•°æ®å¢å¼ºä»£ç :")
        print("""
# ä½¿ç”¨librosaè¿›è¡Œæ•°æ®å¢å¼º
import librosa
import numpy as np
from scipy.signal import butter, lfilter

def augment_audio(audio, sr=16000):
    augmented = []
    
    # 1. æ·»åŠ å™ªéŸ³
    noise = np.random.normal(0, 0.005, audio.shape)
    augmented.append(audio + noise)
    
    # 2. è°ƒæ•´éŸ³è°ƒ
    for pitch_shift in [-2, -1, 1, 2]:
        pitched = librosa.effects.pitch_shift(audio, sr, pitch_shift)
        augmented.append(pitched)
    
    # 3. æ—¶é—´æ‹‰ä¼¸
    for rate in [0.9, 1.1]:
        stretched = librosa.effects.time_stretch(audio, rate)
        augmented.append(stretched)
    
    # 4. æ·»åŠ æ··å“
    reverb = np.convolve(audio, np.random.exponential(0.1, 1000))
    augmented.append(reverb[:len(audio)])
    
    return augmented
        """)
        
        print("\n" + "="*50)
        print("è´Ÿæ ·æœ¬æ”¶é›†ç­–ç•¥")
        print("="*50)
        
        print("\nâŒ è´Ÿæ ·æœ¬ç±»å‹:")
        print("â€¢ å…¶ä»–éŸ©è¯­è¯æ±‡: ì•ˆë…•í•˜ì„¸ìš”, ê°ì‚¬í•©ë‹ˆë‹¤, ì£„ì†¡í•©ë‹ˆë‹¤")
        print("â€¢ ç±»ä¼¼å‘éŸ³: í•˜ì´, ë„›ì§€, í•˜ì´ë¸Œë¦¬ë“œ")
        print("â€¢ ç¯å¢ƒå£°éŸ³: ìŒì•…, TV, ëŒ€í™”, êµí†µì†ŒìŒ")
        print("â€¢ å…¶ä»–è¯­è¨€: Hello, Hi there, Hey Google")
        
        print("\nğŸ¯ è´Ÿæ ·æœ¬æ”¶é›†æ¯”ä¾‹:")
        print("â€¢ æ­£æ ·æœ¬: 100-200ä¸ª")
        print("â€¢ è´Ÿæ ·æœ¬: 300-600ä¸ª (2-3å€)")
        
        print("\n" + "="*50)
        print("è´¨é‡æ§åˆ¶æ£€æŸ¥æ¸…å•")
        print("="*50)
        
        print("\nâœ… éŸ³é¢‘è´¨é‡æ£€æŸ¥:")
        print("â–¡ é‡‡æ ·ç‡: 16kHz")
        print("â–¡ ä½æ·±åº¦: 16-bit")
        print("â–¡ å£°é“: å•å£°é“")
        print("â–¡ é•¿åº¦: 1-3ç§’")
        print("â–¡ éŸ³é‡: é€‚ä¸­ï¼Œæ— å‰Šæ³¢")
        print("â–¡ å™ªéŸ³: æœ€å°èƒŒæ™¯å™ªéŸ³")
        print("â–¡ æ¸…æ™°åº¦: è¯­éŸ³æ¸…æ™°å¯è¾¨")
        
        print("\nğŸ“Š æ•°æ®é›†å¹³è¡¡:")
        print("â–¡ æ€§åˆ«å¹³è¡¡: ç”·å¥³æ¯”ä¾‹é€‚å½“")
        print("â–¡ å¹´é¾„åˆ†å¸ƒ: æ¶µç›–ä¸åŒå¹´é¾„æ®µ")
        print("â–¡ å£éŸ³å˜åŒ–: åŒ…å«ä¸åŒåœ°åŒºå£éŸ³")
        print("â–¡ ç¯å¢ƒå¤šæ ·: ä¸åŒå½•éŸ³ç¯å¢ƒ")
        
        print("\nğŸ”§ æŠ€æœ¯éªŒè¯:")
        print("â–¡ æ–‡ä»¶æ ¼å¼æ­£ç¡®")
        print("â–¡ æ–‡ä»¶å®Œæ•´æ— æŸå")
        print("â–¡ æ ‡æ³¨å‡†ç¡®")
        print("â–¡ ç›®å½•ç»“æ„æ­£ç¡®")
        
        print("\n" + "="*80)
        print("ğŸš€ å¼€å§‹æ”¶é›†æ•°æ®!")
        print("="*80)
        print("é€‰æ‹©ä¸€ç§æˆ–å¤šç§æ–¹æ³•å¼€å§‹æ”¶é›†è®­ç»ƒæ•°æ®ã€‚")
        print("å»ºè®®ä»TTSåˆæˆå¼€å§‹ï¼Œç„¶åè¡¥å……çœŸäººå½•éŸ³ã€‚")
        print("è®°ä½ï¼šæ•°æ®è´¨é‡æ¯”æ•°é‡æ›´é‡è¦ï¼")
        print("="*80)
    
    def generate_tts_samples_gtts(self, count: int = 50):
        """ä½¿ç”¨Google TTSç”Ÿæˆæ ·æœ¬"""
        try:
            from gtts import gTTS
            from pydub import AudioSegment
            import io
        except ImportError:
            logger.error("è¯·å®‰è£…ä¾èµ–: pip install gtts pydub")
            return False
        
        logger.info(f"ä½¿ç”¨Google TTSç”Ÿæˆ {count} ä¸ªæ ·æœ¬...")
        
        # ä¸åŒçš„TTSå‚æ•°
        lang_variants = ['ko']
        slow_variants = [False, True]
        
        sample_count = 0
        for i in range(count):
            try:
                # éšæœºé€‰æ‹©å‚æ•°
                lang = random.choice(lang_variants)
                slow = random.choice(slow_variants)
                
                # ç”ŸæˆTTS
                tts = gTTS(text=self.wake_word, lang=lang, slow=slow)
                
                # ä¿å­˜åˆ°å†…å­˜
                mp3_fp = io.BytesIO()
                tts.write_to_fp(mp3_fp)
                mp3_fp.seek(0)
                
                # è½¬æ¢ä¸ºWAV
                audio = AudioSegment.from_mp3(mp3_fp)
                audio = audio.set_frame_rate(16000).set_channels(1)
                
                # éšæœºéŸ³é¢‘å¢å¼º
                if random.random() > 0.5:
                    # éšæœºéŸ³é‡è°ƒæ•´ (-3dB to +3dB)
                    volume_change = random.uniform(-3, 3)
                    audio = audio + volume_change
                
                # ä¿å­˜æ–‡ä»¶
                filename = f"gtts_{lang}_{slow}_{sample_count:03d}.wav"
                filepath = self.positive_dir / filename
                audio.export(str(filepath), format="wav")
                
                sample_count += 1
                if sample_count % 10 == 0:
                    logger.info(f"å·²ç”Ÿæˆ {sample_count} ä¸ªTTSæ ·æœ¬")
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.5)
                
            except Exception as e:
                logger.error(f"ç”ŸæˆTTSæ ·æœ¬å¤±è´¥: {e}")
                continue
        
        logger.info(f"TTSæ ·æœ¬ç”Ÿæˆå®Œæˆï¼Œå…± {sample_count} ä¸ªæ–‡ä»¶")
        return True
    
    def generate_negative_samples_tts(self, count: int = 100):
        """ç”Ÿæˆè´Ÿæ ·æœ¬"""
        try:
            from gtts import gTTS
            from pydub import AudioSegment
            import io
        except ImportError:
            logger.error("è¯·å®‰è£…ä¾èµ–: pip install gtts pydub")
            return False
        
        # éŸ©è¯­è´Ÿæ ·æœ¬è¯æ±‡
        negative_words = [
            "ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤", "ì£„ì†¡í•©ë‹ˆë‹¤", "ê´œì°®ìŠµë‹ˆë‹¤",
            "í•˜ì´", "ë„›ì§€", "í•˜ì´ë¸Œë¦¬ë“œ", "ì•ˆë…•", "ì—¬ë³´ì„¸ìš”",
            "êµ¬ê¸€", "ì‹œë¦¬", "ì•Œë ‰ì‚¬", "ë¹…ìŠ¤ë¹„"
        ]
        
        logger.info(f"ç”Ÿæˆ {count} ä¸ªè´Ÿæ ·æœ¬...")
        
        sample_count = 0
        for i in range(count):
            try:
                # éšæœºé€‰æ‹©è´Ÿæ ·æœ¬è¯æ±‡
                word = random.choice(negative_words)
                
                # ç”ŸæˆTTS
                tts = gTTS(text=word, lang='ko', slow=random.choice([True, False]))
                
                # ä¿å­˜åˆ°å†…å­˜
                mp3_fp = io.BytesIO()
                tts.write_to_fp(mp3_fp)
                mp3_fp.seek(0)
                
                # è½¬æ¢ä¸ºWAV
                audio = AudioSegment.from_mp3(mp3_fp)
                audio = audio.set_frame_rate(16000).set_channels(1)
                
                # ä¿å­˜æ–‡ä»¶
                filename = f"negative_tts_{word}_{sample_count:03d}.wav"
                # æ›¿æ¢æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦
                filename = filename.replace(" ", "_").replace(".", "")
                filepath = self.negative_dir / filename
                audio.export(str(filepath), format="wav")
                
                sample_count += 1
                if sample_count % 20 == 0:
                    logger.info(f"å·²ç”Ÿæˆ {sample_count} ä¸ªè´Ÿæ ·æœ¬")
                
                time.sleep(0.3)
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆè´Ÿæ ·æœ¬å¤±è´¥: {e}")
                continue
        
        logger.info(f"è´Ÿæ ·æœ¬ç”Ÿæˆå®Œæˆï¼Œå…± {sample_count} ä¸ªæ–‡ä»¶")
        return True
    
    def create_recording_script(self):
        """åˆ›å»ºå½•éŸ³è„šæœ¬"""
        script_content = f"""#!/bin/bash
# éŸ©è¯­å”¤é†’è¯å½•éŸ³è„šæœ¬

echo "ğŸ™ï¸ éŸ©è¯­å”¤é†’è¯å½•éŸ³åŠ©æ‰‹"
echo "ç›®æ ‡è¯æ±‡: {self.wake_word}"
echo "è¯·å‡†å¤‡å¥½éº¦å…‹é£ï¼Œåœ¨å®‰é™ç¯å¢ƒä¸­å½•éŸ³"
echo ""

# åˆ›å»ºå½•éŸ³ç›®å½•
mkdir -p "{self.positive_dir}"
mkdir -p "{self.negative_dir}"

# å½•éŸ³å‡½æ•°
record_positive() {{
    echo "ğŸ“¢ è¯·è¯´: {self.wake_word}"
    echo "æŒ‰å›è½¦å¼€å§‹å½•éŸ³ï¼Œå½•éŸ³3ç§’åè‡ªåŠ¨åœæ­¢..."
    read
    
    filename="manual_$(date +%Y%m%d_%H%M%S).wav"
    filepath="{self.positive_dir}/$filename"
    
    echo "ğŸ”´ å½•éŸ³ä¸­... (3ç§’)"
    sox -d -r 16000 -c 1 -b 16 "$filepath" trim 0 3
    echo "âœ… å½•éŸ³å®Œæˆ: $filename"
    
    # æ’­æ”¾å½•éŸ³ç¡®è®¤
    echo "ğŸ”Š æ’­æ”¾å½•éŸ³ç¡®è®¤:"
    play "$filepath"
}}

# æ‰¹é‡å½•éŸ³
echo "å¼€å§‹æ‰¹é‡å½•éŸ³æ­£æ ·æœ¬..."
for i in {{1..20}}; do
    echo ""
    echo "=== ç¬¬ $i ä¸ªæ ·æœ¬ ==="
    record_positive
    
    echo "ç»§ç»­ä¸‹ä¸€ä¸ª? (y/n)"
    read -n 1 continue_recording
    echo ""
    
    if [[ $continue_recording != "y" ]]; then
        break
    fi
done

echo ""
echo "ğŸ‰ å½•éŸ³å®Œæˆ!"
echo "æ­£æ ·æœ¬ä¿å­˜åœ¨: {self.positive_dir}"
echo "è¯·æ£€æŸ¥å½•éŸ³è´¨é‡ï¼Œåˆ é™¤ä¸åˆæ ¼çš„æ–‡ä»¶"
"""
        
        script_path = self.output_dir / "record_samples.sh"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod(script_path, 0o755)
        
        logger.info(f"å½•éŸ³è„šæœ¬å·²åˆ›å»º: {script_path}")
        return script_path
    
    def validate_samples(self):
        """éªŒè¯æ”¶é›†çš„æ ·æœ¬"""
        try:
            import librosa
        except ImportError:
            logger.error("è¯·å®‰è£…librosa: pip install librosa")
            return False
        
        logger.info("éªŒè¯è®­ç»ƒæ ·æœ¬...")
        
        # æ£€æŸ¥æ­£æ ·æœ¬
        positive_files = list(self.positive_dir.glob("*.wav"))
        negative_files = list(self.negative_dir.glob("*.wav"))
        
        logger.info(f"æ­£æ ·æœ¬: {len(positive_files)} ä¸ªæ–‡ä»¶")
        logger.info(f"è´Ÿæ ·æœ¬: {len(negative_files)} ä¸ªæ–‡ä»¶")
        
        # éªŒè¯éŸ³é¢‘æ ¼å¼
        valid_positive = 0
        valid_negative = 0
        
        for file_path in positive_files:
            try:
                y, sr = librosa.load(file_path, sr=16000)
                if len(y) > 0 and sr == 16000:
                    valid_positive += 1
            except Exception as e:
                logger.warning(f"æ— æ•ˆçš„æ­£æ ·æœ¬æ–‡ä»¶: {file_path}")
        
        for file_path in negative_files:
            try:
                y, sr = librosa.load(file_path, sr=16000)
                if len(y) > 0 and sr == 16000:
                    valid_negative += 1
            except Exception as e:
                logger.warning(f"æ— æ•ˆçš„è´Ÿæ ·æœ¬æ–‡ä»¶: {file_path}")
        
        logger.info(f"æœ‰æ•ˆæ­£æ ·æœ¬: {valid_positive}/{len(positive_files)}")
        logger.info(f"æœ‰æ•ˆè´Ÿæ ·æœ¬: {valid_negative}/{len(negative_files)}")
        
        # ç»™å‡ºå»ºè®®
        if valid_positive < 50:
            logger.warning("æ­£æ ·æœ¬æ•°é‡ä¸è¶³ï¼Œå»ºè®®è‡³å°‘50ä¸ª")
        if valid_negative < 100:
            logger.warning("è´Ÿæ ·æœ¬æ•°é‡ä¸è¶³ï¼Œå»ºè®®è‡³å°‘100ä¸ª")
        if valid_negative < valid_positive * 2:
            logger.warning("è´Ÿæ ·æœ¬æ•°é‡åº”è¯¥æ˜¯æ­£æ ·æœ¬çš„2-3å€")
        
        return valid_positive >= 10 and valid_negative >= 20

def main():
    parser = argparse.ArgumentParser(description="æ”¶é›†éŸ©è¯­å”¤é†’è¯è®­ç»ƒæ•°æ®")
    parser.add_argument("--output_dir", default="training_data/korean_wake_word",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--method", choices=["guide", "tts", "record", "validate"],
                       default="guide", help="æ”¶é›†æ–¹æ³•")
    parser.add_argument("--count", type=int, default=50,
                       help="ç”Ÿæˆæ ·æœ¬æ•°é‡")
    
    args = parser.parse_args()
    
    collector = KoreanDataCollector(args.output_dir)
    
    if args.method == "guide":
        collector.show_collection_guide()
    
    elif args.method == "tts":
        print("ğŸ¤– ä½¿ç”¨TTSç”Ÿæˆè®­ç»ƒæ•°æ®...")
        success1 = collector.generate_tts_samples_gtts(args.count)
        success2 = collector.generate_negative_samples_tts(args.count * 2)
        
        if success1 and success2:
            print("âœ… TTSæ ·æœ¬ç”Ÿæˆå®Œæˆ!")
            collector.validate_samples()
        else:
            print("âŒ TTSæ ·æœ¬ç”Ÿæˆå¤±è´¥")
    
    elif args.method == "record":
        print("ğŸ™ï¸ åˆ›å»ºå½•éŸ³è„šæœ¬...")
        script_path = collector.create_recording_script()
        print(f"ğŸ“ å½•éŸ³è„šæœ¬å·²åˆ›å»º: {script_path}")
        print("è¿è¡Œè„šæœ¬å¼€å§‹å½•éŸ³:")
        print(f"bash {script_path}")
    
    elif args.method == "validate":
        print("ğŸ” éªŒè¯è®­ç»ƒæ•°æ®...")
        if collector.validate_samples():
            print("âœ… æ•°æ®éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ!")
        else:
            print("âŒ æ•°æ®ä¸è¶³æˆ–æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥")

if __name__ == "__main__":
    main()
