#!/usr/bin/env python3
"""
éŸ©è¯­å”¤é†’è¯ OpenWakeWord æ¨¡å‹è®­ç»ƒè„šæœ¬
åŸºäºOpenWakeWordæ¡†æ¶è®­ç»ƒè‡ªå®šä¹‰éŸ©è¯­å”¤é†’è¯"í•˜ì´ë„›ì§€"

OpenWakeWordéœ€è¦ä¸‰ä¸ªTensorFlow Liteæ¨¡å‹:
1. melspectrogram.tflite - éŸ³é¢‘è½¬melé¢‘è°±å›¾
2. embedding.tflite - ç‰¹å¾åµŒå…¥æå–  
3. wake.tflite - å”¤é†’è¯åˆ†ç±»å™¨

ä½¿ç”¨æ–¹æ³•:
    python scripts/train_openwakeword_korean.py --data_dir scripts/training_data/korean_wake_word_tts
    python scripts/train_openwakeword_korean.py --data_dir scripts/training_data/korean_wake_word_tts --epochs 100
"""

import os
import sys
import argparse
import logging
import time
from pathlib import Path
import numpy as np
import json
from typing import List, Tuple, Dict, Optional

# éŸ³é¢‘å¤„ç†
try:
    import librosa
    import soundfile as sf
except ImportError:
    print("âŒ ç¼ºå°‘éŸ³é¢‘å¤„ç†åº“: pip install librosa soundfile")
    sys.exit(1)

# TensorFlow
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers
    print(f"âœ… TensorFlowç‰ˆæœ¬: {tf.__version__}")
except ImportError:
    print("âŒ ç¼ºå°‘TensorFlow: pip install tensorflow")
    sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('openwakeword_korean_training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class OpenWakeWordKoreanTrainer:
    """OpenWakeWordéŸ©è¯­å”¤é†’è¯è®­ç»ƒå™¨"""
    
    def __init__(self, data_dir: str, output_dir: str = "models/openwakeword_korean"):
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # OpenWakeWordéŸ³é¢‘å‚æ•° (ä¸Dicioä¸­OwwModel.ktä¿æŒä¸€è‡´)
        self.sample_rate = 16000
        self.mel_input_count = 1152  # MEL_INPUT_COUNT = 512 + 160 * 4
        self.mel_output_count = 5    # (1152 - 512) / 160 + 1 = 5
        self.mel_feature_size = 32   # MEL_FEATURE_SIZE
        
        # åµŒå…¥æ¨¡å‹å‚æ•°
        self.emb_input_count = 76    # EMB_INPUT_COUNT
        self.emb_output_count = 1    # EMB_OUTPUT_COUNT  
        self.emb_feature_size = 96   # EMB_FEATURE_SIZE
        
        # å”¤é†’è¯æ¨¡å‹å‚æ•°
        self.wake_input_count = 16   # WAKE_INPUT_COUNT
        
        # è®­ç»ƒå‚æ•°
        self.batch_size = 32
        self.epochs = 50
        self.learning_rate = 0.001
        self.validation_split = 0.2
        
        logger.info(f"åˆå§‹åŒ–OpenWakeWordè®­ç»ƒå™¨")
        logger.info(f"æ•°æ®ç›®å½•: {self.data_dir}")
        logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        logger.info(f"éŸ³é¢‘å‚æ•°: SR={self.sample_rate}, MEL_INPUT={self.mel_input_count}")
    
    def load_audio_file(self, file_path: Path) -> Optional[np.ndarray]:
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶è°ƒæ•´åˆ°å›ºå®šé•¿åº¦"""
        try:
            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(str(file_path), sr=self.sample_rate)
            
            # è°ƒæ•´é•¿åº¦åˆ°mel_input_count
            if len(y) > self.mel_input_count:
                # å¤ªé•¿åˆ™æˆªå–ä¸­é—´éƒ¨åˆ†
                start = (len(y) - self.mel_input_count) // 2
                y = y[start:start + self.mel_input_count]
            elif len(y) < self.mel_input_count:
                # å¤ªçŸ­åˆ™å¡«å……é›¶
                y = np.pad(y, (0, self.mel_input_count - len(y)))
            
            return y.astype(np.float32)
            
        except Exception as e:
            logger.error(f"åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None
    
    def extract_mel_spectrogram(self, audio: np.ndarray) -> np.ndarray:
        """æå–melé¢‘è°±å›¾ç‰¹å¾ (æ¨¡æ‹Ÿmelspectrogram.tfliteçš„åŠŸèƒ½)"""
        try:
            # è®¡ç®—melé¢‘è°±å›¾
            mel_spec = librosa.feature.melspectrogram(
                y=audio,
                sr=self.sample_rate,
                n_mels=self.mel_feature_size,
                n_fft=512,
                hop_length=160,
                win_length=512,
                fmin=0,
                fmax=self.sample_rate // 2
            )
            
            # è½¬æ¢ä¸ºå¯¹æ•°åˆ»åº¦
            log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)
            
            # æ ‡å‡†åŒ–åˆ° [-1, 1] èŒƒå›´
            log_mel_spec = (log_mel_spec - np.mean(log_mel_spec)) / (np.std(log_mel_spec) + 1e-8)
            log_mel_spec = np.clip(log_mel_spec, -3, 3) / 3.0
            
            # è½¬ç½®ä»¥åŒ¹é…OpenWakeWordæ ¼å¼ [time, mel_bins]
            mel_features = log_mel_spec.T  # Shape: [time_frames, mel_feature_size]
            
            # ç¡®ä¿è¾“å‡ºå½¢çŠ¶æ­£ç¡®
            if mel_features.shape[0] != self.mel_output_count:
                # è°ƒæ•´æ—¶é—´ç»´åº¦
                if mel_features.shape[0] > self.mel_output_count:
                    mel_features = mel_features[:self.mel_output_count]
                else:
                    # å¡«å……
                    pad_width = ((0, self.mel_output_count - mel_features.shape[0]), (0, 0))
                    mel_features = np.pad(mel_features, pad_width, mode='constant')
            
            return mel_features.astype(np.float32)
            
        except Exception as e:
            logger.error(f"æå–melé¢‘è°±å›¾å¤±è´¥: {e}")
            return None
    
    def load_dataset(self) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """åŠ è½½æ•°æ®é›†å¹¶æå–melé¢‘è°±å›¾ç‰¹å¾"""
        logger.info("å¼€å§‹åŠ è½½æ•°æ®é›†å¹¶æå–melç‰¹å¾...")
        
        mel_features_list = []
        labels_list = []
        file_names = []
        
        # åŠ è½½æ­£æ ·æœ¬
        positive_dir = self.data_dir / "positive"
        if positive_dir.exists():
            logger.info(f"åŠ è½½æ­£æ ·æœ¬ä»: {positive_dir}")
            positive_files = list(positive_dir.glob("*.wav"))
            logger.info(f"æ‰¾åˆ° {len(positive_files)} ä¸ªæ­£æ ·æœ¬æ–‡ä»¶")
            
            for i, wav_file in enumerate(positive_files):
                audio = self.load_audio_file(wav_file)
                if audio is not None:
                    mel_features = self.extract_mel_spectrogram(audio)
                    if mel_features is not None:
                        mel_features_list.append(mel_features)
                        labels_list.append(1)  # æ­£æ ·æœ¬æ ‡ç­¾
                        file_names.append(wav_file.name)
                
                if (i + 1) % 20 == 0:
                    logger.info(f"å·²å¤„ç† {i + 1} ä¸ªæ­£æ ·æœ¬")
        
        # åŠ è½½è´Ÿæ ·æœ¬
        negative_dir = self.data_dir / "negative"
        if negative_dir.exists():
            logger.info(f"åŠ è½½è´Ÿæ ·æœ¬ä»: {negative_dir}")
            negative_files = list(negative_dir.glob("*.wav"))
            logger.info(f"æ‰¾åˆ° {len(negative_files)} ä¸ªè´Ÿæ ·æœ¬æ–‡ä»¶")
            
            for i, wav_file in enumerate(negative_files):
                audio = self.load_audio_file(wav_file)
                if audio is not None:
                    mel_features = self.extract_mel_spectrogram(audio)
                    if mel_features is not None:
                        mel_features_list.append(mel_features)
                        labels_list.append(0)  # è´Ÿæ ·æœ¬æ ‡ç­¾
                        file_names.append(wav_file.name)
                
                if (i + 1) % 50 == 0:
                    logger.info(f"å·²å¤„ç† {i + 1} ä¸ªè´Ÿæ ·æœ¬")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        X = np.array(mel_features_list)
        y = np.array(labels_list)
        
        logger.info(f"æ•°æ®é›†åŠ è½½å®Œæˆ:")
        logger.info(f"  æ€»æ ·æœ¬æ•°: {len(X)}")
        logger.info(f"  æ­£æ ·æœ¬æ•°: {np.sum(y == 1)}")
        logger.info(f"  è´Ÿæ ·æœ¬æ•°: {np.sum(y == 0)}")
        logger.info(f"  Melç‰¹å¾å½¢çŠ¶: {X.shape}")
        
        return X, y, file_names
    
    def create_embedding_model(self) -> keras.Model:
        """åˆ›å»ºåµŒå…¥æ¨¡å‹ (æ¨¡æ‹Ÿembedding.tflite)"""
        logger.info("åˆ›å»ºåµŒå…¥æ¨¡å‹...")
        
        # è¾“å…¥: [batch, emb_input_count, mel_feature_size, 1]
        inputs = keras.Input(shape=(self.emb_input_count, self.mel_feature_size, 1), name='mel_input')
        
        # å·ç§¯å±‚æå–ç‰¹å¾
        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
        x = layers.BatchNormalization()(x)
        x = layers.MaxPooling2D((2, 2))(x)
        
        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.MaxPooling2D((2, 2))(x)
        
        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
        x = layers.BatchNormalization()(x)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        x = layers.GlobalAveragePooling2D()(x)
        
        # å…¨è¿æ¥å±‚
        x = layers.Dense(256, activation='relu')(x)
        x = layers.Dropout(0.3)(x)
        x = layers.Dense(self.emb_feature_size, activation='tanh', name='embedding')(x)
        
        # è¾“å‡º: [batch, 1, 1, emb_feature_size]
        outputs = layers.Reshape((1, 1, self.emb_feature_size))(x)
        
        model = keras.Model(inputs, outputs, name='embedding_model')
        return model
    
    def create_wake_model(self) -> keras.Model:
        """åˆ›å»ºå”¤é†’è¯åˆ†ç±»æ¨¡å‹ (æ¨¡æ‹Ÿwake.tflite)"""
        logger.info("åˆ›å»ºå”¤é†’è¯åˆ†ç±»æ¨¡å‹...")
        
        # è¾“å…¥: [batch, wake_input_count, emb_feature_size]
        inputs = keras.Input(shape=(self.wake_input_count, self.emb_feature_size), name='embedding_input')
        
        # LSTMå±‚å¤„ç†æ—¶åºç‰¹å¾
        x = layers.LSTM(128, return_sequences=True)(inputs)
        x = layers.Dropout(0.3)(x)
        x = layers.LSTM(64, return_sequences=False)(x)
        x = layers.Dropout(0.3)(x)
        
        # å…¨è¿æ¥å±‚
        x = layers.Dense(32, activation='relu')(x)
        x = layers.Dropout(0.2)(x)
        
        # è¾“å‡ºå±‚ - äºŒåˆ†ç±» (å”¤é†’è¯ vs éå”¤é†’è¯)
        outputs = layers.Dense(1, activation='sigmoid', name='wake_prediction')(x)
        
        model = keras.Model(inputs, outputs, name='wake_model')
        return model
    
    def create_end_to_end_model(self) -> keras.Model:
        """åˆ›å»ºç«¯åˆ°ç«¯æ¨¡å‹ç”¨äºè®­ç»ƒ"""
        logger.info("åˆ›å»ºç«¯åˆ°ç«¯è®­ç»ƒæ¨¡å‹...")
        
        # Melè¾“å…¥
        mel_inputs = keras.Input(shape=(self.mel_output_count, self.mel_feature_size), name='mel_spectrogram')
        
        # æ¨¡æ‹Ÿmelç‰¹å¾çš„æ—¶åºç´¯ç§¯ (ç®€åŒ–ç‰ˆæœ¬)
        # åœ¨å®é™…OpenWakeWordä¸­ï¼Œè¿™éƒ¨åˆ†ç”±melspectrogram.tfliteå¤„ç†
        mel_expanded = layers.Reshape((self.mel_output_count, self.mel_feature_size, 1))(mel_inputs)
        
        # å¡«å……åˆ°emb_input_counté•¿åº¦
        if self.mel_output_count < self.emb_input_count:
            pad_count = self.emb_input_count - self.mel_output_count
            padding = layers.Lambda(lambda x: tf.pad(x, [[0, 0], [0, pad_count], [0, 0], [0, 0]]))(mel_expanded)
        else:
            padding = mel_expanded
        
        # åµŒå…¥æ¨¡å‹
        embedding_model = self.create_embedding_model()
        embeddings = embedding_model(padding)
        
        # é‡å¡‘ä¸ºæ—¶åºæ ¼å¼
        embeddings_seq = layers.Reshape((1, self.emb_feature_size))(embeddings)
        
        # æ¨¡æ‹Ÿæ—¶åºç´¯ç§¯ (ç®€åŒ–ç‰ˆæœ¬)
        # å¤åˆ¶åµŒå…¥ä»¥åˆ›å»ºæ—¶åº
        embeddings_repeated = layers.Lambda(
            lambda x: tf.tile(x, [1, self.wake_input_count, 1])
        )(embeddings_seq)
        
        # å”¤é†’è¯æ¨¡å‹
        wake_model = self.create_wake_model()
        wake_output = wake_model(embeddings_repeated)
        
        # å®Œæ•´æ¨¡å‹
        full_model = keras.Model(mel_inputs, wake_output, name='korean_wake_word_model')
        
        return full_model, embedding_model, wake_model
    
    def train_model(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """è®­ç»ƒæ¨¡å‹"""
        logger.info("å¼€å§‹è®­ç»ƒOpenWakeWordæ¨¡å‹...")
        
        # åˆ›å»ºæ¨¡å‹
        full_model, embedding_model, wake_model = self.create_end_to_end_model()
        
        # ç¼–è¯‘æ¨¡å‹
        full_model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate),
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        # æ˜¾ç¤ºæ¨¡å‹ç»“æ„
        logger.info("å®Œæ•´æ¨¡å‹ç»“æ„:")
        full_model.summary(print_fn=logger.info)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        # å°†æ ‡ç­¾è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        y_train = y.astype(np.float32)
        
        # åˆ›å»ºå›è°ƒ
        callbacks = [
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True
            ),
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-6
            ),
            keras.callbacks.ModelCheckpoint(
                filepath=str(self.output_dir / "best_model.weights.h5"),
                monitor='val_accuracy',
                save_best_only=True,
                save_weights_only=True  # åªä¿å­˜æƒé‡é¿å…åºåˆ—åŒ–é—®é¢˜
            )
        ]
        
        # è®­ç»ƒæ¨¡å‹
        start_time = time.time()
        logger.info(f"å¼€å§‹è®­ç»ƒï¼Œæ•°æ®å½¢çŠ¶: X={X.shape}, y={y_train.shape}")
        
        history = full_model.fit(
            X, y_train,
            batch_size=self.batch_size,
            epochs=self.epochs,
            validation_split=self.validation_split,
            callbacks=callbacks,
            verbose=1
        )
        
        training_time = time.time() - start_time
        logger.info(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f} ç§’")
        
        # è¯„ä¼°æ¨¡å‹
        val_loss, val_accuracy, val_precision, val_recall = full_model.evaluate(
            X, y_train, verbose=0
        )
        
        logger.info(f"æœ€ç»ˆè¯„ä¼°ç»“æœ:")
        logger.info(f"  éªŒè¯æŸå¤±: {val_loss:.4f}")
        logger.info(f"  éªŒè¯å‡†ç¡®ç‡: {val_accuracy:.4f}")
        logger.info(f"  éªŒè¯ç²¾ç¡®ç‡: {val_precision:.4f}")
        logger.info(f"  éªŒè¯å¬å›ç‡: {val_recall:.4f}")
        
        return {
            'full_model': full_model,
            'embedding_model': embedding_model,
            'wake_model': wake_model,
            'history': history.history,
            'training_time': training_time,
            'final_metrics': {
                'loss': val_loss,
                'accuracy': val_accuracy,
                'precision': val_precision,
                'recall': val_recall
            }
        }
    
    def convert_to_tflite(self, model_info: Dict):
        """è½¬æ¢æ¨¡å‹ä¸ºTensorFlow Liteæ ¼å¼"""
        logger.info("è½¬æ¢æ¨¡å‹ä¸ºTensorFlow Liteæ ¼å¼...")
        
        # åˆ›å»ºç®€åŒ–çš„melæ¨¡å‹ (å®é™…ä¸­è¿™ä¸ªæ¨¡å‹æ¯”è¾ƒå¤æ‚)
        mel_model = self._create_mel_model()
        
        # è½¬æ¢æ¨¡å‹
        models_to_convert = {
            'melspectrogram.tflite': mel_model,
            'embedding.tflite': model_info['embedding_model'],
            'wake.tflite': model_info['wake_model']
        }
        
        for filename, model in models_to_convert.items():
            try:
                logger.info(f"è½¬æ¢ {filename}...")
                
                # åˆ›å»ºTFLiteè½¬æ¢å™¨
                converter = tf.lite.TFLiteConverter.from_keras_model(model)
                
                # ä¼˜åŒ–è®¾ç½®
                converter.optimizations = [tf.lite.Optimize.DEFAULT]
                converter.target_spec.supported_types = [tf.float32]
                
                # è½¬æ¢
                tflite_model = converter.convert()
                
                # ä¿å­˜
                tflite_path = self.output_dir / filename
                with open(tflite_path, 'wb') as f:
                    f.write(tflite_model)
                
                logger.info(f"âœ… {filename} ä¿å­˜åˆ°: {tflite_path}")
                
            except Exception as e:
                logger.error(f"è½¬æ¢ {filename} å¤±è´¥: {e}")
    
    def _create_mel_model(self) -> keras.Model:
        """åˆ›å»ºç®€åŒ–çš„melé¢‘è°±å›¾æ¨¡å‹"""
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…çš„melæ¨¡å‹æ›´å¤æ‚
        inputs = keras.Input(shape=(self.mel_input_count,), name='audio_input')
        
        # ç®€å•çš„çº¿æ€§å˜æ¢ä½œä¸ºå ä½ç¬¦
        x = layers.Reshape((self.mel_input_count, 1))(inputs)
        x = layers.Conv1D(32, 512, strides=160, activation='relu')(x)
        x = layers.Conv1D(self.mel_feature_size, 1, activation='linear')(x)
        
        # è¾“å‡ºå½¢çŠ¶: [batch, mel_output_count, mel_feature_size]
        outputs = layers.Lambda(lambda x: x[:, :self.mel_output_count, :])(x)
        
        model = keras.Model(inputs, outputs, name='mel_spectrogram_model')
        return model
    
    def save_model_info(self, model_info: Dict):
        """ä¿å­˜æ¨¡å‹ä¿¡æ¯å’Œå…ƒæ•°æ®"""
        logger.info("ä¿å­˜æ¨¡å‹ä¿¡æ¯...")
        
        # ä¿å­˜å®Œæ•´æ¨¡å‹
        full_model_path = self.output_dir / "korean_wake_word_full.h5"
        model_info['full_model'].save(full_model_path)
        logger.info(f"å®Œæ•´æ¨¡å‹å·²ä¿å­˜åˆ°: {full_model_path}")
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'wake_word': 'í•˜ì´ë„›ì§€',
            'romanized': 'hi_nutji',
            'model_type': 'OpenWakeWord',
            'training_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'audio_params': {
                'sample_rate': self.sample_rate,
                'mel_input_count': self.mel_input_count,
                'mel_output_count': self.mel_output_count,
                'mel_feature_size': self.mel_feature_size,
                'emb_input_count': self.emb_input_count,
                'emb_feature_size': self.emb_feature_size,
                'wake_input_count': self.wake_input_count
            },
            'training_params': {
                'batch_size': self.batch_size,
                'epochs': self.epochs,
                'learning_rate': self.learning_rate,
                'validation_split': self.validation_split
            },
            'performance': model_info['final_metrics'],
            'training_time_seconds': model_info['training_time'],
            'model_files': [
                'melspectrogram.tflite',
                'embedding.tflite', 
                'wake.tflite'
            ]
        }
        
        metadata_path = self.output_dir / "model_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ¨¡å‹å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {metadata_path}")
        
        return metadata_path

def main():
    parser = argparse.ArgumentParser(description="OpenWakeWordéŸ©è¯­å”¤é†’è¯æ¨¡å‹è®­ç»ƒ")
    parser.add_argument("--data_dir", required=True,
                       help="è®­ç»ƒæ•°æ®ç›®å½• (åŒ…å«positive/å’Œnegative/å­ç›®å½•)")
    parser.add_argument("--output_dir", default="models/openwakeword_korean",
                       help="æ¨¡å‹è¾“å‡ºç›®å½•")
    parser.add_argument("--epochs", type=int, default=50,
                       help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch_size", type=int, default=32,
                       help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--learning_rate", type=float, default=0.001,
                       help="å­¦ä¹ ç‡")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = Path(args.data_dir)
    if not data_dir.exists():
        logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        sys.exit(1)
    
    positive_dir = data_dir / "positive"
    negative_dir = data_dir / "negative"
    
    if not positive_dir.exists() or not negative_dir.exists():
        logger.error("æ•°æ®ç›®å½•å¿…é¡»åŒ…å« positive/ å’Œ negative/ å­ç›®å½•")
        sys.exit(1)
    
    try:
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = OpenWakeWordKoreanTrainer(args.data_dir, args.output_dir)
        trainer.epochs = args.epochs
        trainer.batch_size = args.batch_size
        trainer.learning_rate = args.learning_rate
        
        # åŠ è½½æ•°æ®é›†
        X, y, file_names = trainer.load_dataset()
        
        if len(X) == 0:
            logger.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
            sys.exit(1)
        
        # è®­ç»ƒæ¨¡å‹
        model_info = trainer.train_model(X, y)
        
        # è½¬æ¢ä¸ºTFLite
        trainer.convert_to_tflite(model_info)
        
        # ä¿å­˜æ¨¡å‹ä¿¡æ¯
        metadata_path = trainer.save_model_info(model_info)
        
        logger.info("ğŸ‰ OpenWakeWordè®­ç»ƒå®Œæˆ!")
        logger.info(f"ğŸ“ æ¨¡å‹æ–‡ä»¶ç›®å½•: {trainer.output_dir}")
        logger.info(f"ğŸ“Š æœ€ç»ˆå‡†ç¡®ç‡: {model_info['final_metrics']['accuracy']:.4f}")
        logger.info(f"â±ï¸  è®­ç»ƒæ—¶é—´: {model_info['training_time']:.2f} ç§’")
        
        print(f"\nğŸš€ æ¨¡å‹æ–‡ä»¶:")
        for model_file in ['melspectrogram.tflite', 'embedding.tflite', 'wake.tflite']:
            model_path = trainer.output_dir / model_file
            if model_path.exists():
                print(f"  âœ… {model_file}")
            else:
                print(f"  âŒ {model_file} (è½¬æ¢å¤±è´¥)")
        
        print(f"\nğŸ“± åœ¨Dicioä¸­ä½¿ç”¨:")
        print(f"  1. å°†ä¸‰ä¸ª.tfliteæ–‡ä»¶å¤åˆ¶åˆ° app/src/withModels/assets/models/openWakeWord/")
        print(f"  2. æˆ–è€…é€šè¿‡è®¾ç½®ç•Œé¢å¯¼å…¥è‡ªå®šä¹‰å”¤é†’è¯æ¨¡å‹")
        
    except KeyboardInterrupt:
        logger.info("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
