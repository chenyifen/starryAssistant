/*
 * Dicio SenseVoice Input Device
 * åŸºäºSenseVoiceå¤šè¯­è¨€ASRçš„è¯­éŸ³è¾“å…¥è®¾å¤‡å®ç°
 */

package org.stypox.dicio.io.input.sensevoice

import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.util.Log
import com.k2fsa.sherpa.onnx.Vad
import dagger.hilt.android.qualifiers.ApplicationContext
import kotlinx.coroutines.*
import kotlinx.coroutines.channels.Channel
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import org.stypox.dicio.di.LocaleManager
import org.stypox.dicio.io.input.InputEvent
import org.stypox.dicio.io.input.SttInputDevice
import org.stypox.dicio.io.input.SttState
import org.stypox.dicio.util.DebugLogger
import java.util.concurrent.atomic.AtomicBoolean

/**
 * SenseVoiceè¯­éŸ³è¾“å…¥è®¾å¤‡
 * ç›´æ¥ä½¿ç”¨SenseVoiceè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œä¸ä¾èµ–Vosk
 */
class SenseVoiceInputDevice(
    @ApplicationContext private val appContext: Context,
    private val localeManager: LocaleManager,
) : SttInputDevice {

    companion object {
        private const val TAG = "SenseVoiceInputDevice"
        
        // éŸ³é¢‘å½•åˆ¶é…ç½® (å‚è€ƒdemoçš„é…ç½®)
        private const val SAMPLE_RATE = 16000
        private const val CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO
        private const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT
        private const val AUDIO_SOURCE = MediaRecorder.AudioSource.MIC
        
        // VADå’Œå½•åˆ¶æ§åˆ¶å‚æ•°
        private const val VAD_FRAME_SIZE = 512 // VADå¤„ç†å¸§å¤§å° (32ms @ 16kHz)
        private const val SPEECH_TIMEOUT_MS = 3000L // é™éŸ³3ç§’åè‡ªåŠ¨åœæ­¢
        private const val MAX_RECORDING_DURATION_MS = 30000L // æœ€é•¿å½•åˆ¶æ—¶é—´30ç§’
        private const val MIN_SPEECH_DURATION_MS = 500L // æœ€çŸ­æœ‰æ•ˆè¯­éŸ³æ—¶é—´
    }

    // SenseVoiceè¯†åˆ«å™¨å’ŒVAD
    private var senseVoiceRecognizer: SenseVoiceRecognizer? = null
    private var vad: Vad? = null
    
    // UIçŠ¶æ€ç®¡ç†
    private val _uiState = MutableStateFlow<SttState>(SttState.NotInitialized)
    override val uiState: StateFlow<SttState> = _uiState.asStateFlow()
    
    // æ§åˆ¶æ ‡å¿—
    private val isInitialized = AtomicBoolean(false)
    private val isListening = AtomicBoolean(false)
    private val isRecording = AtomicBoolean(false)
    
    // éŸ³é¢‘å½•åˆ¶ç›¸å…³
    private var audioRecord: AudioRecord? = null
    private var recordingJob: Job? = null
    private var vadJob: Job? = null
    private var eventListener: ((InputEvent) -> Unit)? = null
    private var samplesChannel = Channel<FloatArray>(capacity = Channel.UNLIMITED)
    
    // VADå’Œè¯­éŸ³æ£€æµ‹çŠ¶æ€
    private var speechDetected = false
    private var speechStartTime = 0L
    private var lastSpeechTime = 0L
    private var audioBuffer = arrayListOf<Float>()
    private var partialText = ""
    
    // åç¨‹ä½œç”¨åŸŸ
    private val scope = CoroutineScope(Dispatchers.Default + SupervisorJob())
    
    init {
        Log.d(TAG, "ğŸ¤ SenseVoiceè¾“å…¥è®¾å¤‡æ­£åœ¨åˆå§‹åŒ–...")
        
        // å¼‚æ­¥åˆå§‹åŒ–SenseVoiceå’ŒVAD
        scope.launch {
            initializeComponents()
        }
    }
    
    /**
     * åˆå§‹åŒ–SenseVoiceè¯†åˆ«å™¨å’ŒVAD
     */
    private suspend fun initializeComponents() {
        Log.d(TAG, "ğŸ”§ å¼€å§‹åˆå§‹åŒ–SenseVoiceå’ŒVADç»„ä»¶...")
        _uiState.value = SttState.Loading(thenStartListening = false)
        
        try {
            // æ£€æŸ¥SenseVoiceæ¨¡å‹å¯ç”¨æ€§
            if (!SenseVoiceModelManager.isModelAvailable(appContext)) {
                Log.e(TAG, "âŒ SenseVoiceæ¨¡å‹ä¸å¯ç”¨")
                _uiState.value = SttState.ErrorLoading(Exception("SenseVoiceæ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"))
                return
            }
            
            // æ£€æŸ¥VADæ¨¡å‹å¯ç”¨æ€§
            if (!VadModelManager.isVadModelAvailable(appContext)) {
                Log.w(TAG, "âš ï¸ VADæ¨¡å‹ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€å•èƒ½é‡æ£€æµ‹")
            }
            
            // åˆ›å»ºSenseVoiceè¯†åˆ«å™¨
            senseVoiceRecognizer = SenseVoiceRecognizer.create(appContext)
            if (senseVoiceRecognizer == null) {
                Log.e(TAG, "âŒ SenseVoiceè¯†åˆ«å™¨åˆ›å»ºå¤±è´¥")
                _uiState.value = SttState.ErrorLoading(Exception("SenseVoiceè¯†åˆ«å™¨åˆ›å»ºå¤±è´¥"))
                return
            }
            
            // æš‚æ—¶ç¦ç”¨VADï¼Œé¿å…æ¨¡å‹å…¼å®¹æ€§é—®é¢˜å¯¼è‡´å´©æºƒ
            Log.w(TAG, "âš ï¸ VADæš‚æ—¶ç¦ç”¨ï¼Œä½¿ç”¨èƒ½é‡æ£€æµ‹ä»£æ›¿")
            vad = null
            
            /*
            // åˆ›å»ºVAD (å¦‚æœå¯ç”¨)
            val vadConfig = VadModelManager.createVadConfig(appContext)
            if (vadConfig != null) {
                try {
                    val vadModelPaths = VadModelManager.getVadModelPaths(appContext)
                    vad = if (vadModelPaths?.isFromAssets == true) {
                        Vad(assetManager = appContext.assets, config = vadConfig)
                    } else {
                        Vad(config = vadConfig)
                    }
                    Log.d(TAG, "âœ… VADåˆå§‹åŒ–æˆåŠŸ")
                } catch (e: Exception) {
                    Log.w(TAG, "âš ï¸ VADåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€å•èƒ½é‡æ£€æµ‹", e)
                    vad = null
                }
            }
            */
            
            Log.d(TAG, "âœ… SenseVoiceè¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
            isInitialized.set(true)
            _uiState.value = SttState.Loaded
            
            val senseVoiceInfo = SenseVoiceModelManager.getModelInfo(appContext)
            val vadInfo = VadModelManager.getVadModelInfo(appContext)
            Log.d(TAG, "ğŸ“Š $senseVoiceInfo")
            Log.d(TAG, "ğŸ“Š $vadInfo")
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ åˆå§‹åŒ–ç»„ä»¶å¼‚å¸¸", e)
            _uiState.value = SttState.ErrorLoading(e)
        }
    }
    
    override fun tryLoad(thenStartListeningEventListener: ((InputEvent) -> Unit)?): Boolean {
        Log.d(TAG, "ğŸš€ å°è¯•åŠ è½½å¹¶å¼€å§‹ç›‘å¬...")
        
        if (!isInitialized.get()) {
            Log.w(TAG, "âš ï¸ SenseVoiceæœªåˆå§‹åŒ–ï¼Œæ— æ³•å¼€å§‹ç›‘å¬")
            return false
        }
        
        if (isListening.get()) {
            Log.w(TAG, "âš ï¸ å·²åœ¨ç›‘å¬ä¸­ï¼Œåœæ­¢å½“å‰ç›‘å¬")
            stopListening()
        }
        
        this.eventListener = thenStartListeningEventListener
        
        // å¼€å§‹å½•åˆ¶å’Œè¯†åˆ«
        return startListening()
    }
    
    override fun onClick(eventListener: (InputEvent) -> Unit) {
        Log.d(TAG, "ğŸ–±ï¸ ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥...")
        
        if (isListening.get()) {
            // å¦‚æœæ­£åœ¨ç›‘å¬ï¼Œåœæ­¢ç›‘å¬
            stopListening()
        } else {
            // å¼€å§‹ç›‘å¬
            tryLoad(eventListener)
        }
    }
    
    override fun stopListening() {
        if (!isListening.get()) {
            return
        }
        
        Log.d(TAG, "ğŸ›‘ åœæ­¢è¯­éŸ³ç›‘å¬...")
        isListening.set(false)
        
        // åœæ­¢å½•åˆ¶
        stopRecording()
        
        // å–æ¶ˆVADä»»åŠ¡
        vadJob?.cancel()
        vadJob = null
        
        _uiState.value = SttState.Loaded
    }
    
    override suspend fun destroy() {
        Log.d(TAG, "ğŸ§¹ é”€æ¯SenseVoiceè¾“å…¥è®¾å¤‡...")
        
        try {
            // åœæ­¢æ‰€æœ‰æ´»åŠ¨
            stopListening()
            
            // å…³é—­éŸ³é¢‘é€šé“
            samplesChannel.close()
            
            // é‡Šæ”¾SenseVoiceè¯†åˆ«å™¨
            senseVoiceRecognizer?.release()
            senseVoiceRecognizer = null
            
            // é‡Šæ”¾VADèµ„æº
            try {
                vad?.release()
                vad = null
                Log.d(TAG, "âœ… VADèµ„æºå·²é‡Šæ”¾")
            } catch (e: Exception) {
                Log.w(TAG, "é‡Šæ”¾VADèµ„æºå¤±è´¥", e)
            }
            
            // å–æ¶ˆåç¨‹ä½œç”¨åŸŸ
            scope.cancel()
            
            // é‡ç½®æ‰€æœ‰çŠ¶æ€
            resetVadState()
            
            // æ¸…ç©ºäº‹ä»¶ç›‘å¬å™¨å¼•ç”¨
            eventListener = null
            
            // é‡ç½®çŠ¶æ€
            isInitialized.set(false)
            _uiState.value = SttState.NotInitialized
            
            Log.d(TAG, "âœ… SenseVoiceè¾“å…¥è®¾å¤‡èµ„æºå·²é‡Šæ”¾")
        } catch (e: Exception) {
            Log.e(TAG, "âŒ é”€æ¯SenseVoiceè¾“å…¥è®¾å¤‡å¤±è´¥", e)
        }
    }
    
    /**
     * å¼€å§‹ç›‘å¬
     */
    private fun startListening(): Boolean {
        if (!isInitialized.get() || senseVoiceRecognizer == null) {
            Log.e(TAG, "âŒ SenseVoiceæœªå‡†å¤‡å¥½ï¼Œæ— æ³•å¼€å§‹ç›‘å¬")
            return false
        }
        
        Log.d(TAG, "ğŸ™ï¸ å¼€å§‹è¯­éŸ³ç›‘å¬...")
        isListening.set(true)
        
        // é‡ç½®VADå’ŒéŸ³é¢‘çŠ¶æ€
        resetVadState()
        
        _uiState.value = SttState.Listening
        
        // å¼€å§‹å½•åˆ¶
        if (startRecording()) {
            // å¯åŠ¨è¶…æ—¶ç›‘æ§ä»»åŠ¡
            vadJob = scope.launch {
                try {
                    delay(MAX_RECORDING_DURATION_MS)
                    // è¾¾åˆ°æœ€å¤§å½•åˆ¶æ—¶é—´ï¼Œè‡ªåŠ¨åœæ­¢
                    Log.d(TAG, "â° è¾¾åˆ°æœ€å¤§å½•åˆ¶æ—¶é—´ï¼Œè‡ªåŠ¨åœæ­¢")
                    stopListeningAndProcess()
                } catch (e: CancellationException) {
                    // æ­£å¸¸å–æ¶ˆï¼Œä¸éœ€è¦å¤„ç†
                }
            }
            return true
        } else {
            Log.e(TAG, "âŒ å¯åŠ¨å½•åˆ¶å¤±è´¥")
            isListening.set(false)
            _uiState.value = SttState.ErrorLoading(Exception("å¯åŠ¨å½•åˆ¶å¤±è´¥"))
            return false
        }
    }
    
    /**
     * å¼€å§‹å½•åˆ¶éŸ³é¢‘ (å‚è€ƒdemoçš„å®ç°)
     */
    private fun startRecording(): Boolean {
        try {
            val bufferSizeInBytes = AudioRecord.getMinBufferSize(
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT
            )
            
            if (bufferSizeInBytes == AudioRecord.ERROR || bufferSizeInBytes == AudioRecord.ERROR_BAD_VALUE) {
                Log.e(TAG, "âŒ æ— æ³•è·å–AudioRecordç¼“å†²åŒºå¤§å°")
                return false
            }
            
            audioRecord = AudioRecord(
                AUDIO_SOURCE,
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT,
                bufferSizeInBytes * 2
            )
            
            if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
                Log.e(TAG, "âŒ AudioRecordåˆå§‹åŒ–å¤±è´¥")
                cleanupAudioRecord()
                return false
            }
            
            // é‡ç½®çŠ¶æ€å·²åœ¨resetVadState()ä¸­å®Œæˆ
            
            audioRecord?.startRecording()
            isRecording.set(true)
            
            Log.d(TAG, "ğŸµ å¼€å§‹å½•åˆ¶éŸ³é¢‘...")
            
            // å¯åŠ¨éŸ³é¢‘é‡‡é›†åç¨‹ (å‚è€ƒdemo)
            recordingJob = scope.launch(Dispatchers.IO) {
                recordAudioData()
            }
            
            // å¯åŠ¨éŸ³é¢‘å¤„ç†åç¨‹
            vadJob = scope.launch(Dispatchers.Default) {
                processAudioForRecognition()
            }
            
            return true
        } catch (e: Exception) {
            Log.e(TAG, "âŒ å¯åŠ¨å½•åˆ¶å¼‚å¸¸", e)
            cleanupAudioRecord()
            return false
        }
    }
    
    /**
     * æ¸…ç†AudioRecordèµ„æº
     */
    private fun cleanupAudioRecord() {
        try {
            audioRecord?.let { record ->
                try {
                    if (record.state == AudioRecord.STATE_INITIALIZED) {
                        if (record.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                            record.stop()
                        }
                    }
                } catch (e: Exception) {
                    Log.w(TAG, "åœæ­¢AudioRecordæ—¶å‡ºé”™", e)
                } finally {
                    try {
                        record.release()
                    } catch (e: Exception) {
                        Log.w(TAG, "é‡Šæ”¾AudioRecordæ—¶å‡ºé”™", e)
                    }
                }
            }
            audioRecord = null
        } catch (e: Exception) {
            Log.e(TAG, "âŒ æ¸…ç†AudioRecordèµ„æºå¤±è´¥", e)
        }
    }
    
    /**
     * å½•åˆ¶éŸ³é¢‘æ•°æ® (å‚è€ƒdemoçš„å®ç°)
     */
    private suspend fun recordAudioData() {
        Log.d(TAG, "ğŸ”„ å¼€å§‹éŸ³é¢‘æ•°æ®å½•åˆ¶...")
        
        val bufferSize = VAD_FRAME_SIZE // ä½¿ç”¨VADå¸§å¤§å°
        val buffer = ShortArray(bufferSize)
        
        while (isRecording.get() && !Thread.currentThread().isInterrupted) {
            try {
                val readSamples = audioRecord?.read(buffer, 0, buffer.size) ?: 0
                
                if (readSamples > 0) {
                    // è½¬æ¢ä¸ºFloatæ•°ç»„ (å‚è€ƒdemo)
                    val samples = FloatArray(readSamples) { buffer[it] / 32768.0f }
                    samplesChannel.send(samples)
                    
                } else if (readSamples < 0) {
                    Log.e(TAG, "âŒ è¯»å–éŸ³é¢‘æ•°æ®é”™è¯¯: $readSamples")
                    break
                }
                
                yield()
                
            } catch (e: Exception) {
                if (isRecording.get()) {
                    Log.e(TAG, "âŒ å½•åˆ¶éŸ³é¢‘æ•°æ®å¼‚å¸¸", e)
                }
                break
            }
        }
        
        // å‘é€ç©ºæ•°ç»„è¡¨ç¤ºç»“æŸ
        val samples = FloatArray(0)
        samplesChannel.send(samples)
        
        Log.d(TAG, "ğŸ éŸ³é¢‘æ•°æ®å½•åˆ¶ç»“æŸ")
    }
    
    /**
     * å¤„ç†éŸ³é¢‘è¿›è¡ŒVADæ£€æµ‹å’Œè¯†åˆ«
     */
    private suspend fun processAudioForRecognition() {
        Log.d(TAG, "ğŸ§  å¼€å§‹éŸ³é¢‘å¤„ç†å’ŒVADæ£€æµ‹...")
        
        while (isListening.get()) {
            for (samples in samplesChannel) {
                if (samples.isEmpty()) {
                    Log.d(TAG, "æ”¶åˆ°ç©ºéŸ³é¢‘æ•°æ®ï¼Œå¤„ç†ç»“æŸ")
                    break
                }
                
                // æ·»åŠ åˆ°ç¼“å†²åŒº
                audioBuffer.addAll(samples.toList())
                
                // VADæ£€æµ‹
                val isSpeech = detectSpeech(samples)
                val currentTime = System.currentTimeMillis()
                
                if (isSpeech) {
                    if (!speechDetected) {
                        // è¯­éŸ³å¼€å§‹
                        speechDetected = true
                        speechStartTime = currentTime
                        Log.d(TAG, "ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
                        
                        // å‘é€è¯­éŸ³å¼€å§‹äº‹ä»¶ (å¯é€‰)
                        withContext(Dispatchers.Main) {
                            // eventListener?.invoke(InputEvent.Partial(""))
                        }
                    }
                    lastSpeechTime = currentTime
                    
                    // è¿›è¡Œå®æ—¶è¯†åˆ« (æ¯éš”ä¸€å®šæ—¶é—´)
                    if (audioBuffer.size >= SAMPLE_RATE) { // 1ç§’çš„éŸ³é¢‘
                        performPartialRecognition()
                    }
                    
                } else if (speechDetected) {
                    // æ£€æŸ¥æ˜¯å¦é™éŸ³è¶…æ—¶
                    val silenceDuration = currentTime - lastSpeechTime
                    if (silenceDuration > SPEECH_TIMEOUT_MS) {
                        Log.d(TAG, "ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³è¶…æ—¶ï¼Œåœæ­¢ç›‘å¬")
                        stopListeningAndProcess()
                        break
                    }
                }
                
                // æ£€æŸ¥æœ€å¤§å½•åˆ¶æ—¶é—´
                if (speechDetected && (currentTime - speechStartTime) > MAX_RECORDING_DURATION_MS) {
                    Log.d(TAG, "â° è¾¾åˆ°æœ€å¤§å½•åˆ¶æ—¶é—´ï¼Œåœæ­¢ç›‘å¬")
                    stopListeningAndProcess()
                    break
                }
            }
        }
        
        Log.d(TAG, "ğŸ éŸ³é¢‘å¤„ç†ç»“æŸ")
    }
    
    /**
     * VADè¯­éŸ³æ£€æµ‹
     */
    private fun detectSpeech(audioSamples: FloatArray): Boolean {
        return if (vad != null) {
            try {
                // ä½¿ç”¨SherpaOnnx VADè¿›è¡Œæ£€æµ‹
                vad!!.acceptWaveform(audioSamples)
                val isSpeech = vad!!.isSpeechDetected()
                vad!!.clear() // æ¸…é™¤VADçŠ¶æ€ï¼Œå‡†å¤‡ä¸‹ä¸€å¸§
                isSpeech
            } catch (e: Exception) {
                Log.w(TAG, "VADæ£€æµ‹å¼‚å¸¸ï¼Œä½¿ç”¨èƒ½é‡æ£€æµ‹", e)
                detectSpeechByEnergy(audioSamples)
            }
        } else {
            // é™çº§åˆ°ç®€å•èƒ½é‡æ£€æµ‹
            detectSpeechByEnergy(audioSamples)
        }
    }
    
    /**
     * ç®€å•çš„èƒ½é‡æ£€æµ‹ï¼ˆVADé™çº§æ–¹æ¡ˆï¼‰
     */
    private fun detectSpeechByEnergy(audioSamples: FloatArray): Boolean {
        if (audioSamples.isEmpty()) return false
        
        // è®¡ç®—RMSèƒ½é‡
        var sum = 0.0
        for (sample in audioSamples) {
            sum += (sample * sample).toDouble()
        }
        val rms = kotlin.math.sqrt(sum / audioSamples.size)
        
        // ç®€å•çš„é˜ˆå€¼æ£€æµ‹
        return rms > 0.01 // å¯è°ƒæ•´çš„é˜ˆå€¼
    }
    
    /**
     * æ‰§è¡Œéƒ¨åˆ†è¯†åˆ«ï¼ˆå®æ—¶åé¦ˆï¼‰
     */
    private suspend fun performPartialRecognition() {
        try {
            val recognizer = senseVoiceRecognizer ?: return
            
            if (audioBuffer.size < SAMPLE_RATE / 2) { // è‡³å°‘0.5ç§’çš„éŸ³é¢‘
                return
            }
            
            // ä½¿ç”¨æœ€è¿‘çš„éŸ³é¢‘è¿›è¡Œè¯†åˆ«
            val audioData = audioBuffer.takeLast(SAMPLE_RATE * 2).toFloatArray() // æœ€è¿‘2ç§’
            val newText = recognizer.recognize(audioData)
            
            if (newText.isNotBlank() && newText != partialText) {
                partialText = newText
                
                // å‘é€éƒ¨åˆ†è¯†åˆ«ç»“æœ
                withContext(Dispatchers.Main) {
                    eventListener?.invoke(InputEvent.Partial(partialText))
                }
                
                DebugLogger.logRecognition(TAG, "éƒ¨åˆ†è¯†åˆ«: \"$partialText\"")
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ éƒ¨åˆ†è¯†åˆ«å¼‚å¸¸", e)
        }
    }
    
    /**
     * åœæ­¢ç›‘å¬å¹¶å¤„ç†æœ€ç»ˆç»“æœ
     */
    private suspend fun stopListeningAndProcess() {
        isListening.set(false)
        stopRecording()
        
        // å¤„ç†æœ€ç»ˆè¯†åˆ«ç»“æœ
        performFinalRecognition()
    }
    
    /**
     * æ‰§è¡Œæœ€ç»ˆè¯†åˆ« (ä½¿ç”¨SenseVoiceçš„æ–¹å¼)
     */
    private suspend fun performFinalRecognition() {
        try {
            val recognizer = senseVoiceRecognizer ?: return
            
            // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¯­éŸ³æ•°æ®
            if (audioBuffer.isEmpty() || !speechDetected) {
                withContext(Dispatchers.Main) {
                    eventListener?.invoke(InputEvent.None)
                }
                _uiState.value = SttState.Loaded
                return
            }
            
            // æ£€æŸ¥è¯­éŸ³æ—¶é•¿æ˜¯å¦è¶³å¤Ÿ
            val speechDuration = System.currentTimeMillis() - speechStartTime
            if (speechDuration < MIN_SPEECH_DURATION_MS) {
                Log.d(TAG, "è¯­éŸ³æ—¶é•¿å¤ªçŸ­ (${speechDuration}ms)ï¼Œå¿½ç•¥")
                withContext(Dispatchers.Main) {
                    eventListener?.invoke(InputEvent.None)
                }
                _uiState.value = SttState.Loaded
                return
            }
            
            Log.d(TAG, "ğŸš€ å¼€å§‹æœ€ç»ˆè¯†åˆ«ï¼ŒéŸ³é¢‘é•¿åº¦: ${audioBuffer.size}æ ·æœ¬ï¼Œè¯­éŸ³æ—¶é•¿: ${speechDuration}ms")
            
            // ä½¿ç”¨SenseVoiceçš„recognizeæ–¹æ³•è¿›è¡Œæœ€ç»ˆè¯†åˆ«
            val audioData = audioBuffer.toFloatArray()
            val finalText = recognizer.recognize(audioData)
            
            DebugLogger.logRecognition(TAG, "æœ€ç»ˆè¯†åˆ«ç»“æœ: \"$finalText\"")
            
            withContext(Dispatchers.Main) {
                if (finalText.isNotBlank()) {
                    eventListener?.invoke(InputEvent.Final(listOf(Pair(finalText, 1.0f))))
                } else {
                    eventListener?.invoke(InputEvent.None)
                }
            }
            
            _uiState.value = SttState.Loaded
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ æœ€ç»ˆè¯†åˆ«å¼‚å¸¸", e)
            withContext(Dispatchers.Main) {
                eventListener?.invoke(InputEvent.Error(e))
            }
            _uiState.value = SttState.ErrorLoading(e)
        } finally {
            // é‡ç½®çŠ¶æ€
            resetVadState()
        }
    }
    
    /**
     * é‡ç½®VADå’Œè¯­éŸ³æ£€æµ‹çŠ¶æ€
     */
    private fun resetVadState() {
        speechDetected = false
        speechStartTime = 0L
        lastSpeechTime = 0L
        audioBuffer.clear()
        partialText = ""
        
        // é‡ç½®VADçŠ¶æ€
        try {
            vad?.reset()
        } catch (e: Exception) {
            Log.w(TAG, "é‡ç½®VADçŠ¶æ€å¤±è´¥", e)
        }
    }
    
    /**
     * åœæ­¢å½•åˆ¶éŸ³é¢‘
     */
    private fun stopRecording() {
        if (!isRecording.get()) {
            return
        }
        
        Log.d(TAG, "ğŸ”‡ åœæ­¢å½•åˆ¶éŸ³é¢‘...")
        isRecording.set(false)
        
        // å–æ¶ˆå½•åˆ¶åç¨‹
        recordingJob?.cancel()
        recordingJob = null
        
        cleanupAudioRecord()
    }
    
    /**
     * è·å–è®¾å¤‡ä¿¡æ¯
     */
    fun getDeviceInfo(): String {
        val recognizerInfo = senseVoiceRecognizer?.getInfo() ?: "æœªåˆå§‹åŒ–"
        val bufferSize = audioBuffer.size
        val isActive = isListening.get()
        return "SenseVoiceDevice($recognizerInfo, ç¼“å†²åŒº:${bufferSize}æ ·æœ¬, æ´»è·ƒ:$isActive)"
    }
}
