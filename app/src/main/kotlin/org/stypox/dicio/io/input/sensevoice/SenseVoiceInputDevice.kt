/*
 * Dicio SenseVoice Input Device
 * åŸºäºSenseVoiceå¤šè¯­è¨€ASRçš„è¯­éŸ³è¾“å…¥è®¾å¤‡å®ç°
 */

package org.stypox.dicio.io.input.sensevoice

import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.util.Log
import com.k2fsa.sherpa.onnx.Vad
import dagger.hilt.android.qualifiers.ApplicationContext
import kotlinx.coroutines.*
import kotlinx.coroutines.channels.Channel
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import org.stypox.dicio.di.LocaleManager
import org.stypox.dicio.io.input.InputEvent
import org.stypox.dicio.io.input.SttInputDevice
import org.stypox.dicio.io.input.SttState
import org.stypox.dicio.util.DebugLogger
import java.util.concurrent.atomic.AtomicBoolean

/**
 * SenseVoiceè¯­éŸ³è¾“å…¥è®¾å¤‡ - å•ä¾‹æ¨¡å¼
 * ç›´æ¥ä½¿ç”¨SenseVoiceè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œä¸ä¾èµ–Vosk
 * ä½¿ç”¨å•ä¾‹æ¨¡å¼é¿å…å¤šå®ä¾‹å†²çª
 */
class SenseVoiceInputDevice private constructor(
    private val appContext: Context,
    private val localeManager: LocaleManager,
) : SttInputDevice {

    companion object {
        private const val TAG = "SenseVoiceInputDevice"
        
        // éŸ³é¢‘å½•åˆ¶é…ç½® (å‚è€ƒdemoçš„é…ç½®)
        private const val SAMPLE_RATE = 16000
        private const val CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO
        private const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT
        private const val AUDIO_SOURCE = MediaRecorder.AudioSource.MIC
        
        // VADå’Œå½•åˆ¶æ§åˆ¶å‚æ•°
        private const val VAD_FRAME_SIZE = 512 // VADå¤„ç†å¸§å¤§å° (32ms @ 16kHz)
        private const val SPEECH_TIMEOUT_MS = 4000L // é™éŸ³8ç§’åè‡ªåŠ¨åœæ­¢ï¼Œç»™ç”¨æˆ·æ›´å¤šæ€è€ƒæ—¶é—´
        private const val MAX_RECORDING_DURATION_MS = 30000L // æœ€é•¿å½•åˆ¶æ—¶é—´30ç§’
        private const val MIN_SPEECH_DURATION_MS = 500L // æœ€çŸ­æœ‰æ•ˆè¯­éŸ³æ—¶é—´

        // å•ä¾‹å®ä¾‹
        @Volatile
        private var INSTANCE: SenseVoiceInputDevice? = null
        

        /**
         * è·å–å•ä¾‹å®ä¾‹
         */
        fun getInstance(appContext: Context, localeManager: LocaleManager): SenseVoiceInputDevice {
            return INSTANCE ?: synchronized(this) {
                INSTANCE ?: SenseVoiceInputDevice(appContext, localeManager).also { 
                    INSTANCE = it
                    Log.d(TAG, "ğŸ—ï¸ åˆ›å»ºSenseVoiceInputDeviceå•ä¾‹å®ä¾‹")
                }
            }
        }

        /**
         * é‡ç½®å•ä¾‹å®ä¾‹ï¼ˆç”¨äºæµ‹è¯•æˆ–é‡æ–°åˆå§‹åŒ–ï¼‰
         */
        fun resetInstance() {
            synchronized(this) {
                INSTANCE?.let { instance ->
                    Log.d(TAG, "ğŸ”„ é‡ç½®SenseVoiceInputDeviceå•ä¾‹å®ä¾‹")
                    // æ¸…ç†å½“å‰å®ä¾‹ - ä½¿ç”¨åç¨‹
                    kotlinx.coroutines.CoroutineScope(kotlinx.coroutines.Dispatchers.Default).launch {
                        instance.destroy()
                    }
                }
                INSTANCE = null
            }
        }
    }

    // SenseVoiceè¯†åˆ«å™¨å’ŒVAD
    private var senseVoiceRecognizer: SenseVoiceRecognizer? = null
    private var vad: Vad? = null
    
    // UIçŠ¶æ€ç®¡ç†
    private val _uiState = MutableStateFlow<SttState>(SttState.NotInitialized)
    override val uiState: StateFlow<SttState> = _uiState.asStateFlow()
    
    // æ§åˆ¶æ ‡å¿—
    private val isInitialized = AtomicBoolean(false)
    private val isListening = AtomicBoolean(false)
    private val isRecording = AtomicBoolean(false)
    
    // éŸ³é¢‘å½•åˆ¶ç›¸å…³
    private var audioRecord: AudioRecord? = null
    private var recordingJob: Job? = null
    private var vadJob: Job? = null
    private var eventListener: ((InputEvent) -> Unit)? = null
    private var samplesChannel = Channel<FloatArray>(capacity = Channel.UNLIMITED)
    
    // VADå’Œè¯­éŸ³æ£€æµ‹çŠ¶æ€
    private var speechDetected = false
    private var speechStartTime = 0L
    private var lastSpeechTime = 0L
    // å‚è€ƒSherpaOnnxSimulateAsrä½¿ç”¨ArrayListè¿›è¡Œé«˜æ•ˆç¼“å†²ç®¡ç†
    private val audioBuffer = arrayListOf<Float>()
    private var bufferOffset = 0
    private val maxBufferSize = SAMPLE_RATE * 10 // æœ€å¤šå­˜å‚¨10ç§’éŸ³é¢‘
    private var partialText = ""
    private var lastPartialRecognitionTime = 0L
    private val PARTIAL_RECOGNITION_COOLDOWN_MS = 200L // å‚è€ƒdemoæ”¹ä¸º200msè§¦å‘é—´éš”
    private var isPartialResultAdded = false // å‚è€ƒdemoçš„ç»“æœç®¡ç†ç­–ç•¥
    
    // åç¨‹ä½œç”¨åŸŸ - ä½¿ç”¨å¯é‡æ–°åˆ›å»ºçš„ä½œç”¨åŸŸ
    private var scope = CoroutineScope(Dispatchers.Default + SupervisorJob())
    
    init {
        Log.d(TAG, "ğŸ¤ SenseVoiceè¾“å…¥è®¾å¤‡æ­£åœ¨åˆå§‹åŒ–...")
        
        // å¼‚æ­¥åˆå§‹åŒ–SenseVoiceå’ŒVAD
        scope.launch {
            initializeComponents()
        }
    }
    
    /**
     * åˆå§‹åŒ–SenseVoiceè¯†åˆ«å™¨å’ŒVAD
     */
    private suspend fun initializeComponents() {
        Log.d(TAG, "ğŸ”§ å¼€å§‹åˆå§‹åŒ–SenseVoiceå’ŒVADç»„ä»¶...")
        _uiState.value = SttState.Loading(thenStartListening = false)
        
        try {
            // æ£€æŸ¥SenseVoiceæ¨¡å‹å¯ç”¨æ€§
            if (!SenseVoiceModelManager.isModelAvailable(appContext)) {
                Log.e(TAG, "âŒ SenseVoiceæ¨¡å‹ä¸å¯ç”¨")
                _uiState.value = SttState.ErrorLoading(Exception("SenseVoiceæ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶"))
                return
            }
            
            // æ£€æŸ¥VADæ¨¡å‹å¯ç”¨æ€§
            if (!VadModelManager.isVadModelAvailable(appContext)) {
                Log.w(TAG, "âš ï¸ VADæ¨¡å‹ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€å•èƒ½é‡æ£€æµ‹")
            }
            
            // åˆ›å»ºSenseVoiceè¯†åˆ«å™¨
            senseVoiceRecognizer = SenseVoiceRecognizer.create(appContext)
            if (senseVoiceRecognizer == null) {
                Log.e(TAG, "âŒ SenseVoiceè¯†åˆ«å™¨åˆ›å»ºå¤±è´¥")
                _uiState.value = SttState.ErrorLoading(Exception("SenseVoiceè¯†åˆ«å™¨åˆ›å»ºå¤±è´¥"))
                return
            }
            
            // æš‚æ—¶ç¦ç”¨VADï¼Œé¿å…æ¨¡å‹å…¼å®¹æ€§é—®é¢˜å¯¼è‡´å´©æºƒ
            Log.w(TAG, "âš ï¸ VADæš‚æ—¶ç¦ç”¨ï¼Œä½¿ç”¨èƒ½é‡æ£€æµ‹ä»£æ›¿")
            vad = null
            
            /*
            // åˆ›å»ºVAD (å¦‚æœå¯ç”¨)
            val vadConfig = VadModelManager.createVadConfig(appContext)
            if (vadConfig != null) {
                try {
                    val vadModelPaths = VadModelManager.getVadModelPaths(appContext)
                    vad = if (vadModelPaths?.isFromAssets == true) {
                        Vad(assetManager = appContext.assets, config = vadConfig)
                    } else {
                        Vad(config = vadConfig)
                    }
                    Log.d(TAG, "âœ… VADåˆå§‹åŒ–æˆåŠŸ")
                } catch (e: Exception) {
                    Log.w(TAG, "âš ï¸ VADåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€å•èƒ½é‡æ£€æµ‹", e)
                    vad = null
                }
            }
            */
            
            Log.d(TAG, "âœ… SenseVoiceè¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
            isInitialized.set(true)
            _uiState.value = SttState.Loaded
            
            val senseVoiceInfo = SenseVoiceModelManager.getModelInfo(appContext)
            val vadInfo = VadModelManager.getVadModelInfo(appContext)
            Log.d(TAG, "ğŸ“Š $senseVoiceInfo")
            Log.d(TAG, "ğŸ“Š $vadInfo")
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ åˆå§‹åŒ–ç»„ä»¶å¼‚å¸¸", e)
            _uiState.value = SttState.ErrorLoading(e)
        }
    }
    
    override fun tryLoad(thenStartListeningEventListener: ((InputEvent) -> Unit)?): Boolean {
        Log.d(TAG, "ğŸš€ å°è¯•åŠ è½½å¹¶å¼€å§‹ç›‘å¬...")
        
        // ç¡®ä¿åç¨‹ä½œç”¨åŸŸå¯ç”¨
        if (!scope.isActive) {
            recreateScope()
        }
        
        if (!isInitialized.get()) {
            Log.w(TAG, "âš ï¸ SenseVoiceæœªåˆå§‹åŒ–ï¼Œæ— æ³•å¼€å§‹ç›‘å¬")
            return false
        }
        
        if (isListening.get()) {
            Log.w(TAG, "âš ï¸ å·²åœ¨ç›‘å¬ä¸­ï¼Œåœæ­¢å½“å‰ç›‘å¬")
            stopListening()
        }
        
        this.eventListener = thenStartListeningEventListener
        
        // å¼€å§‹å½•åˆ¶å’Œè¯†åˆ«
        return startListening()
    }
    
    override fun onClick(eventListener: (InputEvent) -> Unit) {
        Log.d(TAG, "ğŸ–±ï¸ ç‚¹å‡»å¼€å§‹è¯­éŸ³è¾“å…¥...")
        
        if (isListening.get()) {
            // å¦‚æœæ­£åœ¨ç›‘å¬ï¼Œåœæ­¢ç›‘å¬
            stopListening()
        } else {
            // å¼€å§‹ç›‘å¬
            tryLoad(eventListener)
        }
    }
    
    override fun stopListening() {
        if (!isListening.get()) {
            return
        }
        
        Log.d(TAG, "ğŸ›‘ åœæ­¢è¯­éŸ³ç›‘å¬...")
        isListening.set(false)
        
        // åœæ­¢å½•åˆ¶
        stopRecording()
        
        // å–æ¶ˆVADä»»åŠ¡
        vadJob?.cancel()
        vadJob = null
        
        _uiState.value = SttState.Loaded
    }
    
    /**
     * å¼ºåˆ¶åœæ­¢å½•åˆ¶ï¼ˆå•ä¾‹æ¨¡å¼ä¸‹çš„åœæ­¢æ–¹æ³•ï¼‰
     */
    fun forceStop() {
        Log.w(TAG, "âš ï¸ å•ä¾‹å®ä¾‹è¢«å¼ºåˆ¶åœæ­¢")
        isListening.set(false)
        isRecording.set(false)
        cleanupAudioRecord()
    }
    
    override suspend fun destroy() {
        Log.d(TAG, "ğŸ§¹ é”€æ¯SenseVoiceè¾“å…¥è®¾å¤‡...")
        
        try {
            // åœæ­¢æ‰€æœ‰æ´»åŠ¨
            stopListening()
            
            // å…³é—­éŸ³é¢‘é€šé“
            samplesChannel.close()
            
            // é‡Šæ”¾SenseVoiceè¯†åˆ«å™¨
            senseVoiceRecognizer?.release()
            senseVoiceRecognizer = null
            
            // é‡Šæ”¾VADèµ„æº
            try {
                vad?.release()
                vad = null
                Log.d(TAG, "âœ… VADèµ„æºå·²é‡Šæ”¾")
            } catch (e: Exception) {
                Log.w(TAG, "é‡Šæ”¾VADèµ„æºå¤±è´¥", e)
            }
            
            // ä¸å–æ¶ˆåç¨‹ä½œç”¨åŸŸï¼Œä¿æŒå•ä¾‹å¯é‡ç”¨
            // scope.cancel() // æ³¨é‡Šæ‰ï¼Œå•ä¾‹æ¨¡å¼ä¸‹ä¿æŒä½œç”¨åŸŸæ´»è·ƒ
            
            // é‡ç½®æ‰€æœ‰çŠ¶æ€
            resetVadState()
            
            // æ¸…ç©ºäº‹ä»¶ç›‘å¬å™¨å¼•ç”¨
            eventListener = null
            
            // é‡ç½®çŠ¶æ€
            isInitialized.set(false)
            _uiState.value = SttState.NotInitialized
            
            Log.d(TAG, "âœ… SenseVoiceè¾“å…¥è®¾å¤‡èµ„æºå·²é‡Šæ”¾")
        } catch (e: Exception) {
            Log.e(TAG, "âŒ é”€æ¯SenseVoiceè¾“å…¥è®¾å¤‡å¤±è´¥", e)
        }
    }
    
    /**
     * é‡æ–°åˆ›å»ºåç¨‹ä½œç”¨åŸŸï¼ˆç”¨äºå•ä¾‹é‡ç”¨ï¼‰
     */
    private fun recreateScope() {
        if (scope.isActive) {
            scope.cancel()
        }
        scope = CoroutineScope(Dispatchers.Default + SupervisorJob())
        Log.d(TAG, "ğŸ”„ é‡æ–°åˆ›å»ºåç¨‹ä½œç”¨åŸŸ")
    }

    /**
     * å¼€å§‹ç›‘å¬
     */
    private fun startListening(): Boolean {
        if (!isInitialized.get() || senseVoiceRecognizer == null) {
            Log.e(TAG, "âŒ SenseVoiceæœªå‡†å¤‡å¥½ï¼Œæ— æ³•å¼€å§‹ç›‘å¬")
            return false
        }
        
        // é˜²æ­¢é‡å¤å¯åŠ¨
        if (isListening.get()) {
            Log.w(TAG, "âš ï¸ å·²åœ¨ç›‘å¬ä¸­ï¼Œå¿½ç•¥é‡å¤å¯åŠ¨è¯·æ±‚")
            return true
        }
        
        // ç¡®ä¿åç¨‹ä½œç”¨åŸŸå¯ç”¨
        if (!scope.isActive) {
            recreateScope()
        }
        
        Log.d(TAG, "ğŸ™ï¸ å¼€å§‹è¯­éŸ³ç›‘å¬...")
        isListening.set(true)
        
        // é‡ç½®VADå’ŒéŸ³é¢‘çŠ¶æ€
        resetVadState()
        
        _uiState.value = SttState.Listening
        
        // å¼€å§‹å½•åˆ¶ (ä½¿ç”¨åç¨‹)
        scope.launch {
            if (startRecording()) {
                // å¯åŠ¨è¶…æ—¶ç›‘æ§ä»»åŠ¡
                vadJob = scope.launch {
                    try {
                        delay(MAX_RECORDING_DURATION_MS)
                        // è¾¾åˆ°æœ€å¤§å½•åˆ¶æ—¶é—´ï¼Œè‡ªåŠ¨åœæ­¢
                        Log.d(TAG, "â° è¾¾åˆ°æœ€å¤§å½•åˆ¶æ—¶é—´ï¼Œè‡ªåŠ¨åœæ­¢")
                        stopListeningAndProcess()
                    } catch (e: CancellationException) {
                        // æ­£å¸¸å–æ¶ˆï¼Œä¸éœ€è¦å¤„ç†
                    }
                }
            } else {
                Log.e(TAG, "âŒ å¯åŠ¨å½•åˆ¶å¤±è´¥")
                isListening.set(false)
                _uiState.value = SttState.ErrorLoading(Exception("å¯åŠ¨å½•åˆ¶å¤±è´¥"))
            }
        }
        return true
    }
    
    /**
     * å¼€å§‹å½•åˆ¶éŸ³é¢‘ (ä¿®å¤ç¼“å†²åŒºç®¡ç†é—®é¢˜å’Œå¹¶å‘è®¿é—®)
     */
    private suspend fun startRecording(): Boolean {
        try {
            // é˜²æ­¢åŒä¸€å®ä¾‹é‡å¤å¯åŠ¨å½•åˆ¶
            if (isRecording.get()) {
                Log.w(TAG, "âš ï¸ å®ä¾‹ ${this.hashCode()} å·²åœ¨å½•åˆ¶ä¸­ï¼Œå¿½ç•¥é‡å¤å¯åŠ¨")
                return true
            }
            
            // å•ä¾‹æ¨¡å¼ä¸‹ä¸éœ€è¦èµ„æºé”
            Log.d(TAG, "ğŸµ å•ä¾‹å®ä¾‹å¼€å§‹å½•åˆ¶éŸ³é¢‘...")
            
            // ç¡®ä¿å…ˆæ¸…ç†ä¹‹å‰çš„èµ„æº
            cleanupAudioRecord()
            
            val minBufferSizeInBytes = AudioRecord.getMinBufferSize(
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT
            )
            
            if (minBufferSizeInBytes == AudioRecord.ERROR || minBufferSizeInBytes == AudioRecord.ERROR_BAD_VALUE) {
                Log.e(TAG, "âŒ æ— æ³•è·å–AudioRecordç¼“å†²åŒºå¤§å°")
                return false
            }
            
            // ä½¿ç”¨æ›´å¤§çš„ç¼“å†²åŒºä»¥é¿å…ç¼“å†²åŒºæº¢å‡ºï¼Œè‡³å°‘æ˜¯æœ€å°ç¼“å†²åŒºçš„4å€
            val actualBufferSize = maxOf(minBufferSizeInBytes * 4, VAD_FRAME_SIZE * 2 * 4) // 4å€å®‰å…¨è¾¹ç•Œ
            
            Log.d(TAG, "ğŸ”§ å®ä¾‹ ${this.hashCode()} éŸ³é¢‘ç¼“å†²åŒºé…ç½®: æœ€å°=${minBufferSizeInBytes}å­—èŠ‚, å®é™…=${actualBufferSize}å­—èŠ‚")
            
            audioRecord = AudioRecord(
                AUDIO_SOURCE,
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT,
                actualBufferSize
            )
            
            if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
                Log.e(TAG, "âŒ AudioRecordåˆå§‹åŒ–å¤±è´¥ï¼ŒçŠ¶æ€: ${audioRecord?.state}")
                cleanupAudioRecord()
                return false
            }
            
            // æ£€æŸ¥å½•åˆ¶çŠ¶æ€
            if (audioRecord?.recordingState != AudioRecord.RECORDSTATE_STOPPED) {
                Log.w(TAG, "âš ï¸ AudioRecordä¸åœ¨åœæ­¢çŠ¶æ€: ${audioRecord?.recordingState}")
            }
            
            // å¼€å§‹å½•åˆ¶
            audioRecord?.startRecording()
            
            // éªŒè¯å½•åˆ¶çŠ¶æ€
            if (audioRecord?.recordingState != AudioRecord.RECORDSTATE_RECORDING) {
                Log.e(TAG, "âŒ AudioRecordå¯åŠ¨å½•åˆ¶å¤±è´¥ï¼ŒçŠ¶æ€: ${audioRecord?.recordingState}")
                cleanupAudioRecord()
                return false
            }
            
            isRecording.set(true)
            
            Log.d(TAG, "ğŸµ å®ä¾‹ ${this.hashCode()} å¼€å§‹å½•åˆ¶éŸ³é¢‘ï¼Œç¼“å†²åŒºå¤§å°: ${actualBufferSize}å­—èŠ‚")
            
            // å¯åŠ¨éŸ³é¢‘é‡‡é›†åç¨‹ (ä½¿ç”¨IOè°ƒåº¦å™¨)
            recordingJob = scope.launch(Dispatchers.IO) {
                recordAudioData()
            }
            
            // å¯åŠ¨éŸ³é¢‘å¤„ç†åç¨‹ (ä½¿ç”¨Defaultè°ƒåº¦å™¨)
            vadJob = scope.launch(Dispatchers.Default) {
                processAudioForRecognition()
            }
            
            return true
        } catch (e: SecurityException) {
            Log.e(TAG, "âŒ å½•éŸ³æƒé™ä¸è¶³", e)
            cleanupAudioRecord()
            return false
        } catch (e: Exception) {
            Log.e(TAG, "âŒ å¯åŠ¨å½•åˆ¶å¼‚å¸¸", e)
            cleanupAudioRecord()
            return false
        }
    }
    
    /**
     * æ¸…ç†AudioRecordèµ„æº (ä¿®å¤èµ„æºæ³„æ¼å’ŒçŠ¶æ€ç®¡ç†)
     */
    private fun cleanupAudioRecord() {
        try {
            // å…ˆåœæ­¢å½•åˆ¶æ ‡å¿—
            isRecording.set(false)
            
            // å–æ¶ˆå½•åˆ¶åç¨‹
            recordingJob?.cancel()
            recordingJob = null
            
            // å–æ¶ˆVADåç¨‹
            vadJob?.cancel()
            vadJob = null
            
            // å…³é—­æ ·æœ¬é€šé“
            try {
                samplesChannel.close()
                // é‡æ–°åˆ›å»ºé€šé“ä»¥ä¾›ä¸‹æ¬¡ä½¿ç”¨
                samplesChannel = Channel(capacity = Channel.UNLIMITED)
            } catch (e: Exception) {
                Log.w(TAG, "å…³é—­æ ·æœ¬é€šé“å¤±è´¥", e)
            }
            
            // æ¸…ç†AudioRecord
            audioRecord?.let { record ->
                try {
                    // æ£€æŸ¥å¹¶åœæ­¢å½•åˆ¶
                    if (record.state == AudioRecord.STATE_INITIALIZED) {
                        when (record.recordingState) {
                            AudioRecord.RECORDSTATE_RECORDING -> {
                                Log.d(TAG, "ğŸ›‘ å®ä¾‹ ${this.hashCode()} åœæ­¢AudioRecordå½•åˆ¶")
                                record.stop()
                                
                                // ç­‰å¾…åœæ­¢å®Œæˆ
                                var attempts = 0
                                while (record.recordingState == AudioRecord.RECORDSTATE_RECORDING && attempts < 10) {
                                    Thread.sleep(10)
                                    attempts++
                                }
                                
                                if (record.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                                    Log.w(TAG, "âš ï¸ AudioRecordåœæ­¢è¶…æ—¶")
                                }
                            }
                            AudioRecord.RECORDSTATE_STOPPED -> {
                                Log.d(TAG, "âœ… AudioRecordå·²åœæ­¢")
                            }
                            else -> {
                                Log.w(TAG, "âš ï¸ AudioRecordçŠ¶æ€å¼‚å¸¸: ${record.recordingState}")
                            }
                        }
                    } else {
                        Log.w(TAG, "âš ï¸ AudioRecordçŠ¶æ€ä¸æ˜¯INITIALIZED: ${record.state}")
                    }
                } catch (e: IllegalStateException) {
                    Log.w(TAG, "åœæ­¢AudioRecordæ—¶çŠ¶æ€å¼‚å¸¸", e)
                } catch (e: Exception) {
                    Log.w(TAG, "åœæ­¢AudioRecordæ—¶å‡ºé”™", e)
                }
                
                // é‡Šæ”¾èµ„æº
                try {
                    Log.d(TAG, "ğŸ—‘ï¸ å®ä¾‹ ${this.hashCode()} é‡Šæ”¾AudioRecordèµ„æº")
                    record.release()
                } catch (e: Exception) {
                    Log.w(TAG, "é‡Šæ”¾AudioRecordæ—¶å‡ºé”™", e)
                }
            }
            
            audioRecord = null
            
            Log.d(TAG, "âœ… å•ä¾‹å®ä¾‹ AudioRecordèµ„æºæ¸…ç†å®Œæˆ")
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ æ¸…ç†AudioRecordèµ„æºå¤±è´¥", e)
        }
    }
    
    /**
     * å½•åˆ¶éŸ³é¢‘æ•°æ® (ä¿®å¤ç¼“å†²åŒºç®¡ç†å’Œå¹¶å‘é—®é¢˜)
     */
    private suspend fun recordAudioData() {
        Log.d(TAG, "ğŸ”„ å¼€å§‹éŸ³é¢‘æ•°æ®å½•åˆ¶...")
        
        // ä½¿ç”¨åˆé€‚çš„ç¼“å†²åŒºå¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡AudioRecordçš„ç¼“å†²åŒº
        val bufferSize = VAD_FRAME_SIZE // 512 samples = 1024 bytes
        val buffer = ShortArray(bufferSize)
        var consecutiveErrors = 0
        val maxConsecutiveErrors = 5
        
        try {
            while (isRecording.get() && !Thread.currentThread().isInterrupted && !currentCoroutineContext().job.isCancelled) {
                try {
                    val currentAudioRecord = audioRecord
                    if (currentAudioRecord == null) {
                        Log.w(TAG, "âš ï¸ AudioRecordä¸ºnullï¼Œåœæ­¢å½•åˆ¶")
                        break
                    }
                    
                    // æ£€æŸ¥AudioRecordçŠ¶æ€
                    if (currentAudioRecord.state != AudioRecord.STATE_INITIALIZED) {
                        Log.e(TAG, "âŒ AudioRecordçŠ¶æ€å¼‚å¸¸: ${currentAudioRecord.state}")
                        break
                    }
                    
                    if (currentAudioRecord.recordingState != AudioRecord.RECORDSTATE_RECORDING) {
                        Log.e(TAG, "âŒ AudioRecordå½•åˆ¶çŠ¶æ€å¼‚å¸¸: ${currentAudioRecord.recordingState}")
                        break
                    }
                    
                    // è¯»å–éŸ³é¢‘æ•°æ®ï¼Œä½¿ç”¨åŒæ­¥æ–¹å¼é¿å…ç¼“å†²åŒºé—®é¢˜
                    val readSamples = currentAudioRecord.read(buffer, 0, buffer.size)
                    
                    when {
                        readSamples > 0 -> {
                            // æˆåŠŸè¯»å–æ•°æ®ï¼Œé‡ç½®é”™è¯¯è®¡æ•°
                            consecutiveErrors = 0
                            
                            // è½¬æ¢ä¸ºFloatæ•°ç»„ (å½’ä¸€åŒ–åˆ° -1.0 åˆ° 1.0)
                            val samples = FloatArray(readSamples) { i -> 
                                buffer[i].toFloat() / 32768.0f 
                            }
                            
                            // å‘é€åˆ°å¤„ç†é€šé“
                            if (!samplesChannel.isClosedForSend) {
                                samplesChannel.send(samples)
                            } else {
                                Log.w(TAG, "âš ï¸ æ ·æœ¬é€šé“å·²å…³é—­")
                                break
                            }
                        }
                        
                        readSamples == 0 -> {
                            // æ²¡æœ‰æ•°æ®å¯è¯»ï¼Œç¨å¾®ç­‰å¾…
                            delay(1)
                        }
                        
                        readSamples == AudioRecord.ERROR_INVALID_OPERATION -> {
                            Log.e(TAG, "âŒ AudioRecordæ— æ•ˆæ“ä½œé”™è¯¯")
                            consecutiveErrors++
                        }
                        
                        readSamples == AudioRecord.ERROR_BAD_VALUE -> {
                            Log.e(TAG, "âŒ AudioRecordå‚æ•°é”™è¯¯")
                            consecutiveErrors++
                        }
                        
                        readSamples == AudioRecord.ERROR_DEAD_OBJECT -> {
                            Log.e(TAG, "âŒ AudioRecordå¯¹è±¡å·²æ­»äº¡")
                            break
                        }
                        
                        readSamples < 0 -> {
                            Log.e(TAG, "âŒ AudioRecordè¯»å–é”™è¯¯: $readSamples")
                            consecutiveErrors++
                        }
                    }
                    
                    // å¦‚æœè¿ç»­é”™è¯¯å¤ªå¤šï¼Œåœæ­¢å½•åˆ¶
                    if (consecutiveErrors >= maxConsecutiveErrors) {
                        Log.e(TAG, "âŒ è¿ç»­é”™è¯¯è¿‡å¤š($consecutiveErrors)ï¼Œåœæ­¢å½•åˆ¶")
                        // ç¡®ä¿çŠ¶æ€æ­£ç¡®é‡ç½®
                        isListening.set(false)
                        isRecording.set(false)
                        _uiState.value = SttState.ErrorLoading(Exception("è¿ç»­éŸ³é¢‘é”™è¯¯è¿‡å¤š"))
                        break
                    }
                    
                    // è®©å‡ºCPUæ—¶é—´
                    yield()
                    
                } catch (e: IllegalStateException) {
                    Log.e(TAG, "âŒ AudioRecordçŠ¶æ€å¼‚å¸¸", e)
                    // ç¡®ä¿çŠ¶æ€æ­£ç¡®é‡ç½®
                    isListening.set(false)
                    isRecording.set(false)
                    _uiState.value = SttState.ErrorLoading(e)
                    break
                } catch (e: kotlinx.coroutines.CancellationException) {
                    Log.d(TAG, "ğŸ›‘ å½•åˆ¶åç¨‹è¢«å–æ¶ˆ")
                    // ç¡®ä¿çŠ¶æ€æ­£ç¡®é‡ç½®
                    isListening.set(false)
                    isRecording.set(false)
                    _uiState.value = SttState.Loaded
                    throw e // é‡æ–°æŠ›å‡ºå–æ¶ˆå¼‚å¸¸
                } catch (e: Exception) {
                    if (isRecording.get()) {
                        Log.e(TAG, "âŒ å½•åˆ¶éŸ³é¢‘æ•°æ®å¼‚å¸¸", e)
                        consecutiveErrors++
                        if (consecutiveErrors >= maxConsecutiveErrors) {
                            // ç¡®ä¿çŠ¶æ€æ­£ç¡®é‡ç½®
                            isListening.set(false)
                            isRecording.set(false)
                            _uiState.value = SttState.ErrorLoading(Exception("è¿ç»­éŸ³é¢‘å¼‚å¸¸è¿‡å¤š"))
                            break
                        }
                    } else {
                        // æ­£å¸¸åœæ­¢ï¼Œä¸è®°å½•é”™è¯¯
                        break
                    }
                }
            }
        } finally {
            // å‘é€ç©ºæ•°ç»„è¡¨ç¤ºç»“æŸ
            try {
                if (!samplesChannel.isClosedForSend) {
                    samplesChannel.send(FloatArray(0))
                }
            } catch (e: Exception) {
                Log.w(TAG, "å‘é€ç»“æŸä¿¡å·å¤±è´¥", e)
            }
            
            Log.d(TAG, "ğŸ éŸ³é¢‘æ•°æ®å½•åˆ¶ç»“æŸ")
        }
    }
    
    /**
     * å¤„ç†éŸ³é¢‘è¿›è¡ŒVADæ£€æµ‹å’Œè¯†åˆ«
     */
    private suspend fun processAudioForRecognition() {
        Log.d(TAG, "ğŸ§  å¼€å§‹éŸ³é¢‘å¤„ç†å’ŒVADæ£€æµ‹...")
        
        try {
            while (isListening.get()) {
                for (samples in samplesChannel) {
                    if (samples.isEmpty()) {
                        Log.d(TAG, "æ”¶åˆ°ç©ºéŸ³é¢‘æ•°æ®ï¼Œå¤„ç†ç»“æŸ")
                        break
                    }
                    
                    // å‚è€ƒSherpaOnnxSimulateAsrçš„é«˜æ•ˆç¼“å†²ç®¡ç†
                    synchronized(audioBuffer) {
                        audioBuffer.addAll(samples.toList())
                        // å¦‚æœç¼“å†²åŒºå¤ªå¤§ï¼Œç§»é™¤æ—§æ•°æ®
                        while (audioBuffer.size > maxBufferSize) {
                            audioBuffer.removeAt(0)
                            if (bufferOffset > 0) bufferOffset--
                        }
                    }
                    
                    // VADæ£€æµ‹
                    val isSpeech = detectSpeech(samples)
                    val currentTime = System.currentTimeMillis()
                    
                    if (isSpeech) {
                        if (!speechDetected) {
                            // è¯­éŸ³å¼€å§‹
                            speechDetected = true
                            speechStartTime = currentTime
                            Log.d(TAG, "ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
                            
                            // ä¸å‘é€çŠ¶æ€æ–‡æœ¬ï¼Œé¿å…å¹²æ‰°çœŸå®çš„ASRç»“æœæ˜¾ç¤º
                            // è¯­éŸ³å¼€å§‹äº‹ä»¶ç”±UIçŠ¶æ€ç®¡ç†å™¨å¤„ç†
                        }
                        lastSpeechTime = currentTime
                        
                        // å‚è€ƒSherpaOnnxSimulateAsræ¯200msè¿›è¡Œå®æ—¶è¯†åˆ«
                        val elapsed = currentTime - lastPartialRecognitionTime
                        if (elapsed > PARTIAL_RECOGNITION_COOLDOWN_MS && audioBuffer.size >= SAMPLE_RATE / 2) {
                            performPartialRecognition()
                        }
                        
                    } else if (speechDetected) {
                        // æ£€æŸ¥æ˜¯å¦é™éŸ³è¶…æ—¶
                        val silenceDuration = currentTime - lastSpeechTime
                        if (silenceDuration > SPEECH_TIMEOUT_MS) {
                            Log.d(TAG, "ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³è¶…æ—¶ï¼Œåœæ­¢ç›‘å¬")
                            stopListeningAndProcess()
                            break
                        }
                    }
                    
                    // æ£€æŸ¥æœ€å¤§å½•åˆ¶æ—¶é—´
                    if (speechDetected && (currentTime - speechStartTime) > MAX_RECORDING_DURATION_MS) {
                        Log.d(TAG, "â° è¾¾åˆ°æœ€å¤§å½•åˆ¶æ—¶é—´ï¼Œåœæ­¢ç›‘å¬")
                        stopListeningAndProcess()
                        break
                    }
                }
            }
        } catch (e: kotlinx.coroutines.CancellationException) {
            Log.d(TAG, "ğŸ›‘ éŸ³é¢‘å¤„ç†åç¨‹è¢«å–æ¶ˆ")
            // æ­£å¸¸çš„åç¨‹å–æ¶ˆï¼Œä¸éœ€è¦è®°å½•ä¸ºé”™è¯¯
            throw e // é‡æ–°æŠ›å‡ºå–æ¶ˆå¼‚å¸¸
        } catch (e: Exception) {
            Log.e(TAG, "âŒ éŸ³é¢‘å¤„ç†å¼‚å¸¸", e)
            // è®¾ç½®é”™è¯¯çŠ¶æ€
            _uiState.value = SttState.ErrorLoading(e)
        } finally {
            Log.d(TAG, "ğŸ éŸ³é¢‘å¤„ç†ç»“æŸ")
        }
    }
    
    /**
     * VADè¯­éŸ³æ£€æµ‹
     */
    private fun detectSpeech(audioSamples: FloatArray): Boolean {
        return if (vad != null) {
            try {
                // ä½¿ç”¨SherpaOnnx VADè¿›è¡Œæ£€æµ‹
                vad!!.acceptWaveform(audioSamples)
                val isSpeech = vad!!.isSpeechDetected()
                vad!!.clear() // æ¸…é™¤VADçŠ¶æ€ï¼Œå‡†å¤‡ä¸‹ä¸€å¸§
                isSpeech
            } catch (e: Exception) {
                Log.w(TAG, "VADæ£€æµ‹å¼‚å¸¸ï¼Œä½¿ç”¨èƒ½é‡æ£€æµ‹", e)
                detectSpeechByEnergy(audioSamples)
            }
        } else {
            // é™çº§åˆ°ç®€å•èƒ½é‡æ£€æµ‹
            detectSpeechByEnergy(audioSamples)
        }
    }
    
    /**
     * ç®€å•çš„èƒ½é‡æ£€æµ‹ï¼ˆVADé™çº§æ–¹æ¡ˆï¼‰
     */
    private fun detectSpeechByEnergy(audioSamples: FloatArray): Boolean {
        if (audioSamples.isEmpty()) return false
        
        // è®¡ç®—RMSèƒ½é‡
        var sum = 0.0
        for (sample in audioSamples) {
            sum += (sample * sample).toDouble()
        }
        val rms = kotlin.math.sqrt(sum / audioSamples.size)
        
        // ç®€å•çš„é˜ˆå€¼æ£€æµ‹
        return rms > 0.01 // å¯è°ƒæ•´çš„é˜ˆå€¼
    }
    
    /**
     * æ‰§è¡Œéƒ¨åˆ†è¯†åˆ«ï¼ˆå®æ—¶åé¦ˆï¼‰- å‚è€ƒSherpaOnnxSimulateAsrä¼˜åŒ–
     */
    private suspend fun performPartialRecognition() {
        try {
            val recognizer = senseVoiceRecognizer ?: return
            
            val currentTime = System.currentTimeMillis()
            lastPartialRecognitionTime = currentTime
            
            // å‚è€ƒSherpaOnnxSimulateAsrçš„ç¼“å†²ç®¡ç†æ–¹å¼
            val audioData = synchronized(audioBuffer) {
                if (audioBuffer.size < SAMPLE_RATE / 4) return // è‡³å°‘0.25ç§’éŸ³é¢‘
                audioBuffer.toFloatArray()
            }
            val newText = recognizer.recognize(audioData)
            
            if (newText.isNotBlank() && newText != partialText) {
                val oldText = partialText
                partialText = newText
                
                // å‚è€ƒSherpaOnnxSimulateAsrçš„ç»“æœç®¡ç†ç­–ç•¥
                withContext(Dispatchers.Main) {
                    if (!isPartialResultAdded) {
                        // é¦–æ¬¡æ·»åŠ éƒ¨åˆ†ç»“æœ
                        eventListener?.invoke(InputEvent.Partial(partialText))
                        isPartialResultAdded = true
                    } else {
                        // æ›´æ–°ç°æœ‰éƒ¨åˆ†ç»“æœ
                        eventListener?.invoke(InputEvent.Partial(partialText))
                    }
                }
                
                Log.d(TAG, "ğŸ¯ éƒ¨åˆ†è¯†åˆ«æ›´æ–°: '$oldText' â†’ '$partialText' (éŸ³é¢‘é•¿åº¦: ${audioData.size / SAMPLE_RATE.toFloat()}ç§’)")
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ éƒ¨åˆ†è¯†åˆ«å¼‚å¸¸", e)
        }
    }
    
    /**
     * åœæ­¢ç›‘å¬å¹¶å¤„ç†æœ€ç»ˆç»“æœ
     */
    private suspend fun stopListeningAndProcess() {
        isListening.set(false)
        stopRecording()
        
        // å¤„ç†æœ€ç»ˆè¯†åˆ«ç»“æœ
        performFinalRecognition()
    }
    
    /**
     * æ‰§è¡Œæœ€ç»ˆè¯†åˆ« (ä½¿ç”¨SenseVoiceçš„æ–¹å¼)
     */
    private suspend fun performFinalRecognition() {
        try {
            val recognizer = senseVoiceRecognizer ?: return
            
            // æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¯­éŸ³æ•°æ®
            if (audioBuffer.isEmpty() || !speechDetected) {
                withContext(Dispatchers.Main) {
                    eventListener?.invoke(InputEvent.None)
                }
                _uiState.value = SttState.Loaded
                return
            }
            
            // æ£€æŸ¥è¯­éŸ³æ—¶é•¿æ˜¯å¦è¶³å¤Ÿ
            val speechDuration = System.currentTimeMillis() - speechStartTime
            if (speechDuration < MIN_SPEECH_DURATION_MS) {
                Log.d(TAG, "è¯­éŸ³æ—¶é•¿å¤ªçŸ­ (${speechDuration}ms)ï¼Œå¿½ç•¥")
                withContext(Dispatchers.Main) {
                    eventListener?.invoke(InputEvent.None)
                }
                _uiState.value = SttState.Loaded
                return
            }
            
            Log.d(TAG, "ğŸš€ å¼€å§‹æœ€ç»ˆè¯†åˆ«ï¼ŒéŸ³é¢‘é•¿åº¦: ${audioBuffer.size}æ ·æœ¬ï¼Œè¯­éŸ³æ—¶é•¿: ${speechDuration}ms")
            
            // å®‰å…¨åœ°ä»é˜Ÿåˆ—ä¸­è·å–æ‰€æœ‰éŸ³é¢‘æ•°æ®
            val bufferList = audioBuffer.toList()
            val audioData = bufferList.toFloatArray()
            val finalText = recognizer.recognize(audioData)
            
            DebugLogger.logRecognition(TAG, "æœ€ç»ˆè¯†åˆ«ç»“æœ: \"$finalText\"")
            Log.d(TAG, "ğŸ” è¯†åˆ«ç»“æœè¯¦æƒ…: é•¿åº¦=${finalText.length}, æ˜¯å¦ç©ºç™½=${finalText.isBlank()}")
            
            withContext(Dispatchers.Main) {
                if (finalText.isNotBlank()) {
                    Log.d(TAG, "âœ… å‘é€Finaläº‹ä»¶: \"$finalText\"")
                    eventListener?.invoke(InputEvent.Final(listOf(Pair(finalText, 1.0f))))
                } else {
                    Log.d(TAG, "âš ï¸ è¯†åˆ«ç»“æœä¸ºç©ºï¼Œå‘é€Noneäº‹ä»¶")
                    eventListener?.invoke(InputEvent.None)
                }
            }
            
            _uiState.value = SttState.Loaded
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ æœ€ç»ˆè¯†åˆ«å¼‚å¸¸", e)
            withContext(Dispatchers.Main) {
                eventListener?.invoke(InputEvent.Error(e))
            }
            _uiState.value = SttState.ErrorLoading(e)
        } finally {
            // é‡ç½®çŠ¶æ€
            resetVadState()
        }
    }
    
    /**
     * é‡ç½®VADå’Œè¯­éŸ³æ£€æµ‹çŠ¶æ€
     */
    private fun resetVadState() {
        speechDetected = false
        speechStartTime = 0L
        lastSpeechTime = 0L
        synchronized(audioBuffer) {
            audioBuffer.clear()
            bufferOffset = 0
        }
        partialText = ""
        isPartialResultAdded = false // é‡ç½®ç»“æœç®¡ç†æ ‡å¿—
        
        // é‡ç½®VADçŠ¶æ€
        try {
            vad?.reset()
        } catch (e: Exception) {
            Log.w(TAG, "é‡ç½®VADçŠ¶æ€å¤±è´¥", e)
        }
    }
    
    /**
     * åœæ­¢å½•åˆ¶éŸ³é¢‘
     */
    private fun stopRecording() {
        if (!isRecording.get()) {
            return
        }
        
        Log.d(TAG, "ğŸ”‡ åœæ­¢å½•åˆ¶éŸ³é¢‘...")
        isRecording.set(false)
        
        // å–æ¶ˆå½•åˆ¶åç¨‹
        recordingJob?.cancel()
        recordingJob = null
        
        cleanupAudioRecord()
    }
    
    /**
     * è·å–è®¾å¤‡ä¿¡æ¯
     */
    fun getDeviceInfo(): String {
        val recognizerInfo = senseVoiceRecognizer?.getInfo() ?: "æœªåˆå§‹åŒ–"
        val bufferSize = audioBuffer.size
        val isActive = isListening.get()
        return "SenseVoiceDevice($recognizerInfo, ç¼“å†²åŒº:${bufferSize}æ ·æœ¬, æ´»è·ƒ:$isActive)"
    }
}
