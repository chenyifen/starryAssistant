package org.stypox.dicio.io.speech

import android.content.Context
import android.media.AudioAttributes
import android.media.AudioFormat
import android.media.AudioManager
import android.media.AudioTrack
import android.util.Log
import kotlinx.coroutines.*
import okhttp3.*
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.RequestBody.Companion.toRequestBody
import org.dicio.skill.context.SpeechOutputDevice
import org.json.JSONObject
import org.stypox.dicio.util.WebSocketConfig
import java.io.IOException
import java.util.concurrent.TimeUnit
import java.util.concurrent.atomic.AtomicBoolean

/**
 * äº‘ç«¯ TTS è¯­éŸ³è¾“å‡ºè®¾å¤‡
 * å‚è€ƒ py-xiaozhi-main å®ç°ï¼Œé€šè¿‡ HTTP API è¯·æ±‚æœåŠ¡å™¨è¿›è¡Œè¯­éŸ³åˆæˆ
 * æ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§æ¨¡å¼
 */
class CloudTtsSpeechDevice(
    private val context: Context
) : SpeechOutputDevice {

    companion object {
        private const val TAG = "CloudTtsSpeechDevice"
        private const val SAMPLE_RATE = 24000 // æœåŠ¡å™¨ TTS é‡‡æ ·ç‡
        private const val CHANNEL_CONFIG = AudioFormat.CHANNEL_OUT_MONO
        private const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT
        private const val REQUEST_TIMEOUT = 30L // è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    }

    private val scope = CoroutineScope(Dispatchers.Main + SupervisorJob())
    
    // æ’­æ”¾çŠ¶æ€
    private val isSpeakingFlag = AtomicBoolean(false)
    override val isSpeaking: Boolean
        get() = isSpeakingFlag.get()
    
    // HTTP å®¢æˆ·ç«¯
    private val httpClient: OkHttpClient by lazy {
        OkHttpClient.Builder()
            .connectTimeout(REQUEST_TIMEOUT, TimeUnit.SECONDS)
            .readTimeout(REQUEST_TIMEOUT, TimeUnit.SECONDS)
            .writeTimeout(REQUEST_TIMEOUT, TimeUnit.SECONDS)
            .build()
    }
    
    // éŸ³é¢‘æ’­æ”¾
    private var audioTrack: AudioTrack? = null
    private var playbackJob: Job? = null
    
    // æ’­æ”¾å®Œæˆå›è°ƒåˆ—è¡¨
    private val finishCallbacks = mutableListOf<Runnable>()

    init {
        Log.d(TAG, "ğŸš€ åˆå§‹åŒ– CloudTtsSpeechDevice")
    }

    override fun speak(speechOutput: String) {
        if (speechOutput.isBlank()) {
            return
        }

        Log.d(TAG, "ğŸ—£ï¸ è¯·æ±‚äº‘ç«¯ TTS åˆæˆ: '$speechOutput'")
        
        // åœæ­¢å½“å‰æ’­æ”¾
        stopSpeaking()
        
        // å¼‚æ­¥è¯·æ±‚ TTS åˆæˆ
        scope.launch(Dispatchers.IO) {
            try {
                isSpeakingFlag.set(true)
                
                // æ„å»º TTS è¯·æ±‚
                val audioData = requestTtsSynthesis(speechOutput)
                
                if (audioData != null && audioData.isNotEmpty()) {
                    // æ’­æ”¾éŸ³é¢‘æ•°æ®
                    playAudioData(audioData)
                } else {
                    Log.e(TAG, "âŒ TTS åˆæˆå¤±è´¥ï¼Œæ²¡æœ‰è¿”å›éŸ³é¢‘æ•°æ®")
                    handlePlaybackFinished()
                }
                
            } catch (e: Exception) {
                Log.e(TAG, "âŒ äº‘ç«¯ TTS åˆæˆå¤±è´¥: ${e.message}", e)
                handlePlaybackFinished()
            }
        }
    }

    /**
     * è¯·æ±‚ TTS åˆæˆ
     */
    private suspend fun requestTtsSynthesis(text: String): ByteArray? = withContext(Dispatchers.IO) {
        try {
            // è·å–æœåŠ¡å™¨é…ç½®
            val baseUrl = WebSocketConfig.getHttpUrl(context)
            val ttsUrl = "$baseUrl/api/v1/tts/synthesize"
            
            // æ„å»ºè¯·æ±‚ JSON
            val requestJson = JSONObject().apply {
                put("text", text)
                put("voice", "default") // å¯ä»¥åç»­æ‰©å±•ä¸ºå¯é…ç½®
                put("speed", 1.0)
                put("pitch", 1.0)
                put("volume", 1.0)
                put("format", "pcm") // PCM æ ¼å¼
                put("sample_rate", SAMPLE_RATE)
                put("channels", 1)
            }
            
            Log.d(TAG, "ğŸ“¤ å‘é€ TTS è¯·æ±‚åˆ°: $ttsUrl")
            Log.d(TAG, "ğŸ“‹ è¯·æ±‚å‚æ•°: ${requestJson.toString(2)}")
            
            // æ„å»º HTTP è¯·æ±‚
            val requestBody = requestJson.toString()
                .toRequestBody("application/json".toMediaType())
            
            val request = Request.Builder()
                .url(ttsUrl)
                .post(requestBody)
                .addHeader("Authorization", "Bearer ${WebSocketConfig.getAccessToken(context)}")
                .addHeader("Content-Type", "application/json")
                .addHeader("Accept", "audio/pcm")
                .build()
            
            // å‘é€è¯·æ±‚
            val response = httpClient.newCall(request).execute()
            
            if (response.isSuccessful) {
                val audioData = response.body?.bytes()
                Log.d(TAG, "âœ… TTS åˆæˆæˆåŠŸï¼ŒéŸ³é¢‘æ•°æ®å¤§å°: ${audioData?.size ?: 0} å­—èŠ‚")
                audioData
            } else {
                Log.e(TAG, "âŒ TTS è¯·æ±‚å¤±è´¥: ${response.code} ${response.message}")
                val errorBody = response.body?.string()
                Log.e(TAG, "é”™è¯¯è¯¦æƒ…: $errorBody")
                null
            }
            
        } catch (e: IOException) {
            Log.e(TAG, "âŒ TTS ç½‘ç»œè¯·æ±‚å¤±è´¥: ${e.message}", e)
            null
        } catch (e: Exception) {
            Log.e(TAG, "âŒ TTS è¯·æ±‚å¼‚å¸¸: ${e.message}", e)
            null
        }
    }

    /**
     * æ’­æ”¾éŸ³é¢‘æ•°æ®
     */
    private suspend fun playAudioData(audioData: ByteArray) = withContext(Dispatchers.IO) {
        try {
            // è®¡ç®—éŸ³é¢‘ç¼“å†²åŒºå¤§å°
            val bufferSize = AudioTrack.getMinBufferSize(
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT
            ).coerceAtLeast(audioData.size)
            
            // åˆ›å»º AudioTrack
            audioTrack = AudioTrack.Builder()
                .setAudioAttributes(
                    AudioAttributes.Builder()
                        .setUsage(AudioAttributes.USAGE_MEDIA)
                        .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)
                        .build()
                )
                .setAudioFormat(
                    AudioFormat.Builder()
                        .setEncoding(AUDIO_FORMAT)
                        .setSampleRate(SAMPLE_RATE)
                        .setChannelMask(CHANNEL_CONFIG)
                        .build()
                )
                .setBufferSizeInBytes(bufferSize)
                .setTransferMode(AudioTrack.MODE_STREAM)
                .build()
            
            if (audioTrack?.state != AudioTrack.STATE_INITIALIZED) {
                Log.e(TAG, "âŒ AudioTrack åˆå§‹åŒ–å¤±è´¥")
                handlePlaybackFinished()
                return@withContext
            }
            
            Log.d(TAG, "ğŸµ å¼€å§‹æ’­æ”¾éŸ³é¢‘ï¼Œæ•°æ®å¤§å°: ${audioData.size} å­—èŠ‚")
            
            // å¼€å§‹æ’­æ”¾
            audioTrack?.play()
            
            // å†™å…¥éŸ³é¢‘æ•°æ®
            var bytesWritten = 0
            val chunkSize = 4096
            
            while (bytesWritten < audioData.size && isSpeakingFlag.get()) {
                val remainingBytes = audioData.size - bytesWritten
                val writeSize = minOf(chunkSize, remainingBytes)
                
                val result = audioTrack?.write(
                    audioData,
                    bytesWritten,
                    writeSize
                ) ?: 0
                
                if (result > 0) {
                    bytesWritten += result
                } else {
                    Log.w(TAG, "âš ï¸ AudioTrack å†™å…¥å¤±è´¥: $result")
                    break
                }
                
                // çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡å¿«å†™å…¥
                delay(10)
            }
            
            // ç­‰å¾…æ’­æ”¾å®Œæˆ
            if (isSpeakingFlag.get()) {
                // è®¡ç®—æ’­æ”¾æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
                val durationMs = (audioData.size * 1000L) / (SAMPLE_RATE * 2) // 16ä½PCM
                delay(durationMs)
            }
            
            Log.d(TAG, "âœ… éŸ³é¢‘æ’­æ”¾å®Œæˆ")
            handlePlaybackFinished()
            
        } catch (e: Exception) {
            Log.e(TAG, "âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥: ${e.message}", e)
            handlePlaybackFinished()
        }
    }

    /**
     * å¤„ç†æ’­æ”¾å®Œæˆ
     */
    private fun handlePlaybackFinished() {
        scope.launch(Dispatchers.Main) {
            isSpeakingFlag.set(false)
            
            // æ¸…ç†éŸ³é¢‘èµ„æº
            audioTrack?.apply {
                if (state == AudioTrack.STATE_INITIALIZED) {
                    stop()
                }
                release()
            }
            audioTrack = null
            
            // æ‰§è¡Œå®Œæˆå›è°ƒ
            synchronized(finishCallbacks) {
                finishCallbacks.forEach { it.run() }
                finishCallbacks.clear()
            }
            
            Log.d(TAG, "ğŸ æ’­æ”¾å®Œæˆå¤„ç†ç»“æŸ")
        }
    }

    override fun stopSpeaking() {
        Log.d(TAG, "â¹ï¸ åœæ­¢äº‘ç«¯ TTS æ’­æ”¾")
        
        // å–æ¶ˆæ’­æ”¾ä»»åŠ¡
        playbackJob?.cancel()
        playbackJob = null
        
        // åœæ­¢éŸ³é¢‘æ’­æ”¾
        scope.launch(Dispatchers.IO) {
            isSpeakingFlag.set(false)
            
            audioTrack?.apply {
                if (state == AudioTrack.STATE_INITIALIZED) {
                    stop()
                }
            }
        }
    }

    override fun runWhenFinishedSpeaking(runnable: Runnable) {
        if (isSpeaking) {
            synchronized(finishCallbacks) {
                finishCallbacks.add(runnable)
            }
        } else {
            runnable.run()
        }
    }

    override fun cleanup() {
        Log.d(TAG, "ğŸ§¹ æ¸…ç† CloudTtsSpeechDevice èµ„æº")
        
        stopSpeaking()
        
        // å–æ¶ˆåç¨‹ä½œç”¨åŸŸ
        scope.cancel()
        
        // æ¸…ç† HTTP å®¢æˆ·ç«¯
        httpClient.dispatcher.executorService.shutdown()
        httpClient.connectionPool.evictAll()
    }
}
