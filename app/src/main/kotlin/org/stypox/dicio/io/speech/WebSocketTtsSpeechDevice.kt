package org.stypox.dicio.io.speech

import android.content.Context
import android.media.AudioAttributes
import android.media.AudioFormat
import android.media.AudioManager
import android.media.AudioTrack
import android.util.Log
import kotlinx.coroutines.*
import org.dicio.skill.context.SpeechOutputDevice
import org.json.JSONObject
import org.stypox.dicio.io.net.MessageType
import org.stypox.dicio.io.net.TtsState
import org.stypox.dicio.io.net.WebSocketProtocol
import java.util.concurrent.atomic.AtomicBoolean

/**
 * WebSocket åœ¨çº¿ TTS è¯­éŸ³è¾“å‡ºè®¾å¤‡
 * å‚è€ƒ py-xiaozhi å®ç°ï¼Œé€šè¿‡ WebSocket æ¥æ”¶æœåŠ¡å™¨çš„ TTS éŸ³é¢‘æµ
 */
class WebSocketTtsSpeechDevice(
    private val context: Context,
    private val protocol: WebSocketProtocol
) : SpeechOutputDevice {

    companion object {
        private const val TAG = "WebSocketTtsSpeechDevice"
        private const val SAMPLE_RATE = 24000 // æœåŠ¡å™¨ TTS é‡‡æ ·ç‡
    }

    private val scope = CoroutineScope(Dispatchers.Main + SupervisorJob())
    
    // æ’­æ”¾çŠ¶æ€
    private val isSpeakingFlag = AtomicBoolean(false)
    override val isSpeaking: Boolean
        get() = isSpeakingFlag.get()
    
    // éŸ³é¢‘æ’­æ”¾
    private var audioTrack: AudioTrack? = null
    private var playbackJob: Job? = null
    private val audioBuffer = mutableListOf<ByteArray>()
    private val audioBufferLock = Any()
    
    // æ’­æ”¾å®Œæˆå›è°ƒåˆ—è¡¨
    private val finishCallbacks = mutableListOf<Runnable>()
    
    // å½“å‰æ­£åœ¨æ’­æ”¾çš„å¥å­
    private var currentSentence: String? = null

    init {
        Log.d(TAG, "ğŸš€ åˆå§‹åŒ– WebSocketTtsSpeechDevice")
        setupAudioMessageCallback()
        setupTextMessageCallback()
    }

    /**
     * è®¾ç½®éŸ³é¢‘æ¶ˆæ¯å›è°ƒ
     */
    private fun setupAudioMessageCallback() {
        protocol.onAudioMessage { audioData ->
            scope.launch(Dispatchers.IO) {
                handleIncomingAudio(audioData)
            }
        }
    }

    /**
     * è®¾ç½®æ–‡æœ¬æ¶ˆæ¯å›è°ƒ - å¤„ç† TTS çŠ¶æ€æ¶ˆæ¯
     */
    private fun setupTextMessageCallback() {
        protocol.onTextMessage { message ->
            try {
                val json = JSONObject(message)
                val type = json.optString("type")
                
                if (type == MessageType.TTS) {
                    val state = json.optString("state")
                    when (state) {
                        TtsState.START -> {
                            Log.d(TAG, "ğŸ”Š TTS å¼€å§‹")
                            handleTtsStart()
                        }
                        TtsState.STOP -> {
                            Log.d(TAG, "â¹ï¸ TTS åœæ­¢")
                            handleTtsStop()
                        }
                        TtsState.SENTENCE_START -> {
                            val text = json.optString("text")
                            Log.d(TAG, "ğŸ“ TTS å¥å­å¼€å§‹: '$text'")
                            currentSentence = text
                        }
                    }
                }
            } catch (e: Exception) {
                Log.e(TAG, "å¤„ç†æ–‡æœ¬æ¶ˆæ¯å¤±è´¥: ${e.message}", e)
            }
        }
    }

    override fun speak(speechOutput: String) {
        if (speechOutput.isBlank()) {
            return
        }

        Log.d(TAG, "ğŸ—£ï¸ è¯·æ±‚ TTS åˆæˆ: '$speechOutput'")
        
        // åœæ­¢å½“å‰æ’­æ”¾
        stopSpeaking()
        
        // å‘é€ TTS è¯·æ±‚åˆ°æœåŠ¡å™¨
        scope.launch {
            val message = JSONObject().apply {
                put("type", "tts_request")
                put("text", speechOutput)
            }
            protocol.sendText(message.toString())
        }
    }

    override fun stopSpeaking() {
        if (!isSpeaking) {
            return
        }

        Log.d(TAG, "â¹ï¸ åœæ­¢ TTS æ’­æ”¾")
        
        isSpeakingFlag.set(false)
        playbackJob?.cancel()
        playbackJob = null
        
        audioTrack?.apply {
            if (playState == AudioTrack.PLAYSTATE_PLAYING) {
                stop()
            }
            flush()
            release()
        }
        audioTrack = null
        
        synchronized(audioBufferLock) {
            audioBuffer.clear()
        }
        
        currentSentence = null
        
        // å‘é€åœæ­¢ TTS å‘½ä»¤åˆ°æœåŠ¡å™¨
        scope.launch {
            val message = JSONObject().apply {
                put("type", "command")
                put("action", "stop_tts")
            }
            protocol.sendText(message.toString())
        }
    }

    override fun runWhenFinishedSpeaking(runnable: Runnable) {
        synchronized(finishCallbacks) {
            if (isSpeaking) {
                finishCallbacks.add(runnable)
            } else {
                // å¦‚æœå·²ç»æ’­æ”¾å®Œæˆï¼Œç«‹å³æ‰§è¡Œ
                runnable.run()
            }
        }
    }

    /**
     * å¤„ç† TTS å¼€å§‹äº‹ä»¶
     */
    private fun handleTtsStart() {
        isSpeakingFlag.set(true)
        initializeAudioTrack()
        startPlayback()
    }

    /**
     * å¤„ç† TTS åœæ­¢äº‹ä»¶
     */
    private fun handleTtsStop() {
        // ç­‰å¾…å‰©ä½™éŸ³é¢‘æ’­æ”¾å®Œæˆ
        scope.launch(Dispatchers.IO) {
            // ç­‰å¾…éŸ³é¢‘ç¼“å†²åŒºæ¸…ç©º
            while (synchronized(audioBufferLock) { audioBuffer.isNotEmpty() }) {
                delay(50)
            }
            
            // åœæ­¢æ’­æ”¾
            withContext(Dispatchers.Main) {
                onSpeakingFinished()
            }
        }
    }

    /**
     * å¤„ç†æ¥æ”¶åˆ°çš„éŸ³é¢‘æ•°æ®
     */
    private fun handleIncomingAudio(audioData: ByteArray) {
        if (!isSpeaking) {
            return
        }

        synchronized(audioBufferLock) {
            audioBuffer.add(audioData)
        }
    }

    /**
     * åˆå§‹åŒ– AudioTrack
     */
    private fun initializeAudioTrack() {
        val bufferSize = AudioTrack.getMinBufferSize(
            SAMPLE_RATE,
            AudioFormat.CHANNEL_OUT_MONO,
            AudioFormat.ENCODING_PCM_16BIT
        )

        audioTrack = AudioTrack.Builder()
            .setAudioAttributes(
                AudioAttributes.Builder()
                    .setUsage(AudioAttributes.USAGE_MEDIA)
                    .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)
                    .build()
            )
            .setAudioFormat(
                AudioFormat.Builder()
                    .setEncoding(AudioFormat.ENCODING_PCM_16BIT)
                    .setSampleRate(SAMPLE_RATE)
                    .setChannelMask(AudioFormat.CHANNEL_OUT_MONO)
                    .build()
            )
            .setBufferSizeInBytes(bufferSize)
            .setTransferMode(AudioTrack.MODE_STREAM)
            .build()

        audioTrack?.play()
        Log.d(TAG, "âœ… AudioTrack å·²åˆå§‹åŒ–å¹¶å¼€å§‹æ’­æ”¾")
    }

    /**
     * å¼€å§‹æ’­æ”¾éŸ³é¢‘
     */
    private fun startPlayback() {
        playbackJob = scope.launch(Dispatchers.IO) {
            try {
                while (isSpeaking && isActive) {
                    val audioData = synchronized(audioBufferLock) {
                        if (audioBuffer.isNotEmpty()) {
                            audioBuffer.removeAt(0)
                        } else {
                            null
                        }
                    }

                    if (audioData != null) {
                        // è½¬æ¢ä¸º short æ•°ç»„
                        val shortArray = ShortArray(audioData.size / 2)
                        for (i in shortArray.indices) {
                            val byte1 = audioData[i * 2].toInt() and 0xFF
                            val byte2 = audioData[i * 2 + 1].toInt() and 0xFF
                            shortArray[i] = ((byte2 shl 8) or byte1).toShort()
                        }

                        // å†™å…¥éŸ³é¢‘æ•°æ®
                        audioTrack?.write(shortArray, 0, shortArray.size)
                    } else {
                        // ç¼“å†²åŒºä¸ºç©ºï¼Œç­‰å¾…æ–°æ•°æ®
                        delay(10)
                    }
                }
            } catch (e: Exception) {
                Log.e(TAG, "éŸ³é¢‘æ’­æ”¾å¤±è´¥: ${e.message}", e)
            }
        }
    }

    /**
     * æ’­æ”¾å®Œæˆå›è°ƒ
     */
    private fun onSpeakingFinished() {
        isSpeakingFlag.set(false)
        
        audioTrack?.apply {
            if (playState == AudioTrack.PLAYSTATE_PLAYING) {
                stop()
            }
            release()
        }
        audioTrack = null
        
        Log.d(TAG, "âœ… TTS æ’­æ”¾å®Œæˆ")
        
        // æ‰§è¡Œæ‰€æœ‰å®Œæˆå›è°ƒ
        synchronized(finishCallbacks) {
            finishCallbacks.forEach { it.run() }
            finishCallbacks.clear()
        }
    }

    override fun cleanup() {
        Log.d(TAG, "ğŸ§¹ æ¸…ç† WebSocketTtsSpeechDevice èµ„æº")
        stopSpeaking()
        scope.cancel()
    }
}

