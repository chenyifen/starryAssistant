package org.stypox.dicio.io.wake.onnx

import android.content.Context
import androidx.test.ext.junit.runners.AndroidJUnit4
import androidx.test.platform.app.InstrumentationRegistry
import org.junit.Assert.*
import org.junit.Before
import org.junit.Test
import org.junit.runner.RunWith
import java.io.File
import kotlin.math.sin

/**
 * HiNudge V8 ONNXæ¨¡å‹Androidç«¯æµ‹è¯•
 * 
 * è¿è¡Œæ–¹å¼:
 * ./gradlew connectedAndroidTest --tests "org.stypox.dicio.io.wake.onnx.HiNudgeOnnxV8WakeDeviceTest"
 */
@RunWith(AndroidJUnit4::class)
class HiNudgeOnnxV8WakeDeviceTest {

    private lateinit var context: Context
    private lateinit var wakeDevice: HiNudgeOnnxV8WakeDevice
    
    @Before
    fun setUp() {
        context = InstrumentationRegistry.getInstrumentation().targetContext
        wakeDevice = HiNudgeOnnxV8WakeDevice(context)
    }

    @Test
    fun testModelsAvailability() {
        println("====================================================================")
        println("ğŸ§ª æµ‹è¯•1: æ¨¡å‹æ–‡ä»¶å¯ç”¨æ€§")
        println("====================================================================")
        
        val modelFolder = File(context.filesDir, "hiNudgeOnnxV8")
        val melFile = File(modelFolder, "melspectrogram.onnx")
        val embFile = File(modelFolder, "embedding_model.onnx")
        val wakeFile = File(modelFolder, "korean_wake_word_v8.onnx")
        
        println("ğŸ“ æ¨¡å‹ç›®å½•: ${modelFolder.absolutePath}")
        println("ğŸ“„ æ¨¡å‹æ–‡ä»¶æ£€æŸ¥:")
        println("  - melspectrogram.onnx: ${if (melFile.exists()) "âœ… EXISTS (${melFile.length()} bytes)" else "âŒ MISSING"}")
        println("  - embedding_model.onnx: ${if (embFile.exists()) "âœ… EXISTS (${embFile.length()} bytes)" else "âŒ MISSING"}")
        println("  - korean_wake_word_v8.onnx: ${if (wakeFile.exists()) "âœ… EXISTS (${wakeFile.length()} bytes)" else "âŒ MISSING"}")
        
        // æ£€æŸ¥Assets
        try {
            val assetFiles = context.assets.list("korean_hinudge_onnx")
            println("\nğŸ“¦ Assetsä¸­çš„æ–‡ä»¶:")
            assetFiles?.forEach { println("  - $it") }
        } catch (e: Exception) {
            println("âš ï¸  æ— æ³•åˆ—å‡ºAssets: ${e.message}")
        }
        
        println("====================================================================")
    }

    @Test
    fun testWakeDeviceInitialization() {
        println("====================================================================")
        println("ğŸ§ª æµ‹è¯•2: WakeDeviceåˆå§‹åŒ–")
        println("====================================================================")
        
        // ç­‰å¾…åˆå§‹åŒ–å®Œæˆ
        Thread.sleep(2000)
        
        val state = wakeDevice.state.value
        println("ğŸ“Š å½“å‰çŠ¶æ€: $state")
        
        when (state) {
            is org.stypox.dicio.io.wake.WakeState.Loaded -> {
                println("âœ… æ¨¡å‹å·²åŠ è½½æˆåŠŸ!")
            }
            is org.stypox.dicio.io.wake.WakeState.Loading -> {
                println("â³ æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­...")
            }
            is org.stypox.dicio.io.wake.WakeState.NotLoaded -> {
                println("âš ï¸  æ¨¡å‹æœªåŠ è½½")
            }
            is org.stypox.dicio.io.wake.WakeState.NotDownloaded -> {
                println("âŒ æ¨¡å‹æœªä¸‹è½½")
            }
            is org.stypox.dicio.io.wake.WakeState.ErrorLoading -> {
                println("âŒ åŠ è½½é”™è¯¯: ${state.throwable.message}")
                state.throwable.printStackTrace()
            }
            else -> {
                println("ğŸ¤· æœªçŸ¥çŠ¶æ€: $state")
            }
        }
        
        println("====================================================================")
    }

    @Test
    fun testSyntheticAudioProcessing() {
        println("====================================================================")
        println("ğŸ§ª æµ‹è¯•3: åˆæˆéŸ³é¢‘å¤„ç†")
        println("====================================================================")
        
        // ç­‰å¾…åˆå§‹åŒ–
        Thread.sleep(3000)
        
        // ç”Ÿæˆæµ‹è¯•éŸ³é¢‘ (1280 samples = 80ms @ 16kHz)
        val frameSize = wakeDevice.frameSize()
        val testAudio = generateTestAudio(frameSize)
        
        println("ğŸ”Š æµ‹è¯•éŸ³é¢‘:")
        println("  - Frame size: $frameSize samples")
        println("  - Duration: ${frameSize * 1000 / 16000}ms @ 16kHz")
        println("  - Min amplitude: ${testAudio.minOrNull()}")
        println("  - Max amplitude: ${testAudio.maxOrNull()}")
        
        // å¤„ç†10å¸§
        println("\nğŸ”„ å¤„ç†æµ‹è¯•éŸ³é¢‘...")
        repeat(10) { i ->
            val detected = wakeDevice.processFrame(testAudio)
            println("  Frame ${i + 1}: ${if (detected) "âœ… DETECTED" else "âŒ Not detected"}")
            
            if (detected) {
                println("\nğŸ‰ åœ¨åˆæˆéŸ³é¢‘ä¸Šæ£€æµ‹åˆ°å”¤é†’è¯!")
                println("   (è¿™å¯èƒ½æ˜¯è¯¯æŠ¥ï¼Œå› ä¸ºä½¿ç”¨çš„æ˜¯éšæœºéŸ³é¢‘)")
            }
        }
        
        println("====================================================================")
    }

    @Test
    fun testRealAudioFile() {
        println("====================================================================")
        println("ğŸ§ª æµ‹è¯•4: çœŸå®éŸ³é¢‘æ–‡ä»¶å¤„ç†")
        println("====================================================================")
        
        // ç­‰å¾…åˆå§‹åŒ–
        Thread.sleep(3000)
        
        // å°è¯•ä»assetsåŠ è½½æµ‹è¯•éŸ³é¢‘
        val testAudioFiles = listOf(
            "test_audio/korean_hinudge_test.wav",
            "test_audio/positive_sample.wav",
            "test_audio/test.wav"
        )
        
        var audioLoaded = false
        
        for (audioPath in testAudioFiles) {
            try {
                println("ğŸ“¼ å°è¯•åŠ è½½: $audioPath")
                val audioStream = context.assets.open(audioPath)
                val audioBytes = audioStream.readBytes()
                audioStream.close()
                
                println("âœ… æˆåŠŸåŠ è½½éŸ³é¢‘: ${audioBytes.size} bytes")
                
                // ç®€å•è§£æWAV (è·³è¿‡44å­—èŠ‚å¤´)
                if (audioBytes.size > 44) {
                    val frameSize = wakeDevice.frameSize()
                    val samplesNeeded = frameSize * 2 // 16-bit PCM
                    
                    if (audioBytes.size >= 44 + samplesNeeded) {
                        // æå–PCMæ•°æ®å¹¶è½¬æ¢ä¸ºShortæ•°ç»„
                        val audioData = ShortArray(frameSize) { i ->
                            val byteIndex = 44 + i * 2
                            val low = audioBytes[byteIndex].toInt() and 0xFF
                            val high = audioBytes[byteIndex + 1].toInt() and 0xFF
                            ((high shl 8) or low).toShort()
                        }
                        
                        println("ğŸ”Š éŸ³é¢‘æ•°æ®:")
                        println("  - Samples: ${audioData.size}")
                        println("  - Min: ${audioData.minOrNull()}")
                        println("  - Max: ${audioData.maxOrNull()}")
                        
                        // å¤„ç†éŸ³é¢‘
                        println("\nğŸ”„ å¤„ç†çœŸå®éŸ³é¢‘...")
                        val detected = wakeDevice.processFrame(audioData)
                        println("ğŸ¯ æ£€æµ‹ç»“æœ: ${if (detected) "âœ… æ£€æµ‹åˆ°å”¤é†’è¯!" else "âŒ æœªæ£€æµ‹åˆ°"}")
                        
                        audioLoaded = true
                        break
                    }
                }
            } catch (e: Exception) {
                println("âš ï¸  æ— æ³•åŠ è½½ $audioPath: ${e.message}")
            }
        }
        
        if (!audioLoaded) {
            println("\nâš ï¸  æœªæ‰¾åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼Œå»ºè®®:")
            println("   1. åœ¨ app/src/androidTest/assets/test_audio/ æ”¾ç½®æµ‹è¯•éŸ³é¢‘")
            println("   2. éŸ³é¢‘æ ¼å¼: 16kHz, 16-bit PCM, Mono WAV")
        }
        
        println("====================================================================")
    }

    @Test
    fun testMultipleFrames() {
        println("====================================================================")
        println("ğŸ§ª æµ‹è¯•5: è¿ç»­å¸§å¤„ç†")
        println("====================================================================")
        
        // ç­‰å¾…åˆå§‹åŒ–
        Thread.sleep(3000)
        
        val frameSize = wakeDevice.frameSize()
        var detectionCount = 0
        val totalFrames = 100
        
        println("ğŸ”„ å¤„ç† $totalFrames å¸§...")
        println("   æ¯å¸§: $frameSize samples (${frameSize * 1000 / 16000}ms)")
        
        val startTime = System.currentTimeMillis()
        
        repeat(totalFrames) { i ->
            val testAudio = generateTestAudio(frameSize)
            val detected = wakeDevice.processFrame(testAudio)
            
            if (detected) {
                detectionCount++
                println("  Frame ${i + 1}: âœ… DETECTED")
            }
        }
        
        val endTime = System.currentTimeMillis()
        val totalTime = endTime - startTime
        val avgTimePerFrame = totalTime.toFloat() / totalFrames
        
        println("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        println("  - æ€»å¸§æ•°: $totalFrames")
        println("  - æ£€æµ‹æ¬¡æ•°: $detectionCount")
        println("  - æ£€æµ‹ç‡: ${detectionCount * 100 / totalFrames}%")
        println("  - æ€»è€—æ—¶: ${totalTime}ms")
        println("  - å¹³å‡æ¯å¸§: ${avgTimePerFrame}ms")
        println("  - å®æ—¶å¤„ç†èƒ½åŠ›: ${if (avgTimePerFrame < 80) "âœ… YES" else "âŒ NO"}")
        
        println("====================================================================")
    }

    @Test
    fun testModelInputOutput() {
        println("====================================================================")
        println("ğŸ§ª æµ‹è¯•6: æ¨¡å‹è¾“å…¥è¾“å‡ºéªŒè¯")
        println("====================================================================")
        
        // è¿™ä¸ªæµ‹è¯•éœ€è¦è®¿é—®å†…éƒ¨æ–¹æ³•ï¼Œå¯èƒ½éœ€è¦åå°„æˆ–ä¿®æ”¹ä»£ç 
        // æš‚æ—¶åªæ£€æŸ¥åŸºæœ¬ä¿¡æ¯
        
        val frameSize = wakeDevice.frameSize()
        println("ğŸ“Š æ¨¡å‹å‚æ•°:")
        println("  - Frame size: $frameSize samples")
        println("  - Expected: 1280 samples (80ms @ 16kHz)")
        
        assertEquals("Frame sizeåº”è¯¥æ˜¯1280", 1280, frameSize)
        
        println("âœ… Frame sizeéªŒè¯é€šè¿‡")
        println("====================================================================")
    }

    // ==================== è¾…åŠ©æ–¹æ³• ====================

    /**
     * ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
     * æ··åˆæ­£å¼¦æ³¢ï¼Œæ¨¡æ‹Ÿè¯­éŸ³
     */
    private fun generateTestAudio(samples: Int): ShortArray {
        val audio = ShortArray(samples)
        for (i in 0 until samples) {
            // æ··åˆå¤šä¸ªé¢‘ç‡çš„æ­£å¼¦æ³¢
            val freq1 = 440.0 // A4
            val freq2 = 880.0 // A5
            val t = i.toDouble() / 16000.0
            val value = (sin(2 * Math.PI * freq1 * t) * 0.3 + 
                        sin(2 * Math.PI * freq2 * t) * 0.2) * 32767
            audio[i] = value.toInt().toShort()
        }
        return audio
    }

    /**
     * ç”Ÿæˆé™éŸ³
     */
    private fun generateSilence(samples: Int): ShortArray {
        return ShortArray(samples) { 0 }
    }
}

