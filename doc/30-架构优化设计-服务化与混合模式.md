# Dicio-Android 架构优化设计 - 服务化与混合模式

**文档编号**: 30  
**创建日期**: 2025-01-XX  
**版本**: v1.0  
**目标**: 将dicio-android重构为服务化架构，支持离线+在线混合模式

---

## 一、现有架构分析

### 1.1 核心组件及职责

```
EnhancedFloatingWindowService (入口服务)
├── WakeDeviceWrapper (唤醒词检测)
├── SttInputDeviceWrapper (STT输入设备管理)
│   ├── VoskInputDevice (离线STT - Vosk)
│   ├── SenseVoiceInputDevice (离线STT - SenseVoice)
│   └── TwoPassInputDevice (双识别模式)
├── SkillEvaluator (技能评估器)
│   ├── SkillHandler (技能处理器)
│   └── SkillRanker (技能排序器)
├── VoiceAssistantStateProvider (状态提供者)
│   └── VoiceAssistantStateCoordinator (状态协调器)
└── DraggableFloatingOrb (悬浮球UI)
```

### 1.2 当前数据流

```
用户唤醒/点击 
  → WakeService/FloatingOrb 
  → SttInputDeviceWrapper.tryLoad()
  → SttInputDevice.onClick()
  → 音频采集（在InputDevice内部）
  → VAD检测（在SenseVoiceInputDevice内部）
  → 语音识别（Vosk/SenseVoice）
  → InputEvent (Partial/Final)
  → SkillEvaluator.processInputEvent()
  → SkillRanker.getBest()
  → Skill.generateOutput()
  → SpeechOutputDevice.speak()
  → 状态更新 → VoiceAssistantStateProvider
```

### 1.3 存在的问题

| 问题 | 影响 | 优先级 |
|-----|-----|--------|
| **音频处理分散** | 音频采集、VAD、编解码逻辑分散在各InputDevice中，难以复用 | 高 |
| **缺少服务化层** | 无法被其他应用调用，不够灵活 | 高 |
| **仅支持离线模式** | 无法使用在线ASR/TTS，准确度和功能受限 | 高 |
| **无连接管理** | 缺少WebSocket连接服务，无法实现流式通信 | 高 |
| **状态管理复杂** | 多个状态协调器，状态流转不够清晰 | 中 |
| **缺少Function Calling** | 无法调用远程服务或本地函数 | 中 |

---

## 二、xiaozhi-esp32架构深度分析

### 2.1 核心设计模式

#### 2.1.1 独立的AudioService层

**设计特点**：
- 完全独立的音频处理服务
- 使用3个独立任务（FreeRTOS Task）：
  - `AudioInputTask` - 音频采集
  - `AudioOutputTask` - 音频播放
  - `OpusCodecTask` - 编解码
- 使用队列解耦数据流：
  - `audio_encode_queue_` - 待编码队列
  - `audio_send_queue_` - 待发送队列
  - `audio_decode_queue_` - 待解码队列
  - `audio_playback_queue_` - 待播放队列
- 使用回调机制通知状态变化

**关键代码模式**：
```cpp
// AudioService初始化
void AudioService::Initialize(AudioCodec* codec) {
    // 创建Opus编解码器
    opus_decoder_ = std::make_unique<OpusDecoderWrapper>(...);
    opus_encoder_ = std::make_unique<OpusEncoderWrapper>(...);
    
    // 设置音频处理器回调
    audio_processor_->OnOutput([this](std::vector<int16_t>&& data) {
        PushTaskToEncodeQueue(kAudioTaskTypeEncodeToSendQueue, std::move(data));
    });
    
    // 设置VAD回调
    audio_processor_->OnVadStateChange([this](bool speaking) {
        voice_detected_ = speaking;
        if (callbacks_.on_vad_change) {
            callbacks_.on_vad_change(speaking);
        }
    });
}
```

**Android对应设计**：
```kotlin
class AudioService(private val context: Context) {
    // 使用Kotlin Coroutines替代FreeRTOS Task
    private val captureScope = CoroutineScope(Dispatchers.IO)
    private val processScope = CoroutineScope(Dispatchers.Default)
    
    // 使用Channel替代C++队列
    private val audioEncodeChannel = Channel<AudioBuffer>(capacity = 10)
    private val audioPlaybackChannel = Channel<AudioBuffer>(capacity = 10)
    
    // 回调机制
    var onVadStateChange: ((Boolean) -> Unit)? = null
    var onAudioData: ((FloatArray) -> Unit)? = null
}
```

#### 2.1.2 EventGroup事件驱动

**设计特点**：
- 使用FreeRTOS EventGroup进行任务同步
- 每个事件对应一个bit位
- 任务通过`xEventGroupWaitBits`等待特定事件
- 使用`xEventGroupSetBits`触发事件

**关键代码模式**：
```cpp
// 定义事件位
#define MAIN_EVENT_SCHEDULE (1 << 0)
#define MAIN_EVENT_SEND_AUDIO (1 << 1)
#define MAIN_EVENT_WAKE_WORD_DETECTED (1 << 2)

// 主事件循环
void Application::MainEventLoop() {
    while (true) {
        EventBits_t bits = xEventGroupWaitBits(event_group_, 
            MAIN_EVENT_SCHEDULE | MAIN_EVENT_SEND_AUDIO | ...,
            pdTRUE, pdFALSE, pdMS_TO_TICKS(100));
        
        if (bits & MAIN_EVENT_WAKE_WORD_DETECTED) {
            OnWakeWordDetected();
        }
        if (bits & MAIN_EVENT_SEND_AUDIO) {
            // 发送音频数据
        }
    }
}
```

**Android对应设计**：
```kotlin
// 使用Kotlin Flow + SharedFlow
class EventDispatcher {
    private val _events = MutableSharedFlow<AppEvent>()
    val events: SharedFlow<AppEvent> = _events.asSharedFlow()
    
    suspend fun dispatch(event: AppEvent) {
        _events.emit(event)
    }
}

// 事件监听
scope.launch {
    eventDispatcher.events.collect { event ->
        when (event) {
            is AppEvent.WakeWordDetected -> handleWakeWord()
            is AppEvent.AudioDataReady -> handleAudioData()
        }
    }
}
```

#### 2.1.3 精确的状态机

**设计特点**：
- 明确的状态枚举`DeviceState`
- 状态转换通过`SetDeviceState()`
- 状态变化会触发回调`DeviceStateEventManager`
- 每个状态有明确的进入/退出逻辑

**关键代码模式**：
```cpp
enum DeviceState {
    kDeviceStateIdle,
    kDeviceStateListening,
    kDeviceStateSpeaking,
    // ...
};

void Application::SetDeviceState(DeviceState state) {
    auto previous_state = device_state_;
    device_state_ = state;
    
    // 触发状态变化事件
    DeviceStateEventManager::GetInstance()
        .PostStateChangeEvent(previous_state, state);
}
```

#### 2.1.4 Protocol回调机制

**设计特点**：
- Protocol层使用回调函数处理各种事件
- 支持多种消息类型（JSON、Audio、MCP）
- 统一的消息格式和序列化

**关键代码模式**：
```cpp
class Protocol {
public:
    void OnIncomingJson(std::function<void(const cJSON*)> callback);
    void OnIncomingAudio(std::function<void(std::unique_ptr<AudioStreamPacket>)> callback);
    void OnAudioChannelOpened(std::function<void()> callback);
    
    virtual bool SendAudio(std::unique_ptr<AudioStreamPacket> packet) = 0;
    virtual void SendWakeWordDetected(const std::string& wake_word);
};
```

#### 2.1.5 Schedule任务调度

**设计特点**：
- 使用队列保存待执行的任务
- 主事件循环定期处理任务队列
- 线程安全的任务添加

**关键代码模式**：
```cpp
void Application::Schedule(std::function<void()> callback) {
    std::lock_guard<std::mutex> lock(mutex_);
    main_tasks_.push_back(callback);
    xEventGroupSetBits(event_group_, MAIN_EVENT_SCHEDULE);
}

// 在事件循环中执行
if (bits & MAIN_EVENT_SCHEDULE) {
    std::function<void()> task;
    {
        std::lock_guard<std::mutex> lock(mutex_);
        if (!main_tasks_.empty()) {
            task = std::move(main_tasks_.front());
            main_tasks_.pop_front();
        }
    }
    if (task) {
        task();
    }
}
```

### 2.2 架构优化目标

基于xiaozhi-esp32的设计模式，定义dicio-android的优化目标：

| 优化点 | xiaozhi-esp32实现 | dicio-android实现 | 优先级 |
|--------|------------------|-------------------|--------|
| **独立音频服务** | AudioService + 3个Task | AudioService + Coroutines | 高 |
| **事件驱动架构** | EventGroup + bits | Flow + SharedFlow | 高 |
| **精确状态机** | DeviceState枚举 | AssistantState枚举 | 高 |
| **队列管理** | deque + mutex | Channel | 高 |
| **协议层** | Protocol回调 | ConnectionService | 高 |
| **VAD检测** | 集成在AudioService | 同样集成在AudioService | 中 |
| **Opus编解码** | OpusEncoder/Decoder | 使用现有库 | 中 |
| **任务调度** | Schedule()队列 | Coroutine + Flow | 中 |

### 2.3 关键借鉴点

1. ✅ **服务独立性** - AudioService完全独立，不依赖UI
2. ✅ **队列解耦** - 使用多个队列解耦音频处理流水线
3. ✅ **回调机制** - 通过回调而非轮询获取状态变化
4. ✅ **状态转换验证** - 明确哪些状态转换是合法的
5. ✅ **边收边处理** - 音频采集和处理同时进行
6. ✅ **中断支持** - AbortSpeaking可随时中断TTS

---

## 三、架构优化设计

### 3.1 新增服务层架构

```
EnhancedFloatingWindowService (入口服务 - 保持)
├── AudioService (🆕 音频服务层)
│   ├── AudioCapture (音频采集)
│   ├── AudioProcessor (VAD/AEC处理)
│   ├── AudioCodec (Opus编解码)
│   └── AudioBufferManager (缓冲管理)
│
├── RecognitionService (🆕 识别服务层)
│   ├── OfflineRecognizer (离线识别器)
│   │   ├── VoskRecognizer
│   │   └── SenseVoiceRecognizer
│   ├── OnlineRecognizer (在线识别器)
│   │   └── StreamingASR (WebSocket流式ASR)
│   └── HybridRecognizer (混合识别器)
│       └── 智能切换逻辑
│
├── SynthesisService (🆕 合成服务层)
│   ├── OfflineTTS (SherpaOnnxTTS)
│   └── OnlineTTS (WebSocket流式TTS)
│
├── ConnectionService (🆕 连接服务层)
│   ├── WebSocketClient (WebSocket客户端)
│   ├── ProtocolHandler (协议处理器)
│   └── ReconnectionManager (重连管理)
│
├── StateManager (🔄 状态管理器 - 重构)
│   ├── AssistantState (状态枚举)
│   ├── StateTransition (状态转换规则)
│   └── EventDispatcher (事件分发器)
│
└── 现有组件 (保持/重构)
    ├── WakeDeviceWrapper (保持)
    ├── SkillEvaluator (保持)
    └── DraggableFloatingOrb (保持)
```

### 3.2 关键类设计

#### 3.2.1 AudioService (新增)

```kotlin
/**
 * 独立的音频服务
 * 职责：音频采集、处理、编解码
 */
class AudioService(
    private val context: Context
) {
    // 音频采集
    private val audioCapture: AudioCapture
    
    // VAD检测器
    private val vadDetector: VADDetector
    
    // 音频编解码
    private val audioCodec: AudioCodec
    
    // 音频缓冲队列
    private val audioBufferChannel: Channel<AudioBuffer>
    
    // 状态回调
    var onVadStateChange: ((Boolean) -> Unit)? = null
    var onAudioData: ((FloatArray) -> Unit)? = null
    
    /**
     * 开始录音
     */
    suspend fun startCapture()
    
    /**
     * 停止录音
     */
    fun stopCapture()
    
    /**
     * 播放音频
     */
    suspend fun playAudio(audioData: ByteArray)
    
    /**
     * 编码为Opus
     */
    fun encodeToOpus(pcmData: FloatArray): ByteArray
    
    /**
     * 从Opus解码
     */
    fun decodeFromOpus(opusData: ByteArray): FloatArray
}
```

#### 3.2.2 ConnectionService (新增)

```kotlin
/**
 * WebSocket连接服务
 * 职责：管理与服务器的WebSocket连接
 */
class ConnectionService(
    private val serverUrl: String
) {
    private var webSocket: WebSocket? = null
    
    // 连接状态
    val connectionState: StateFlow<ConnectionState>
    
    // 消息流
    val messageFlow: SharedFlow<ServerMessage>
    
    /**
     * 连接服务器
     */
    suspend fun connect()
    
    /**
     * 断开连接
     */
    fun disconnect()
    
    /**
     * 发送音频数据
     */
    suspend fun sendAudio(audioData: ByteArray)
    
    /**
     * 发送JSON消息
     */
    suspend fun sendJson(json: String)
    
    /**
     * 接收流式ASR结果
     */
    fun observeAsrResults(): Flow<AsrResult>
    
    /**
     * 接收流式TTS音频
     */
    fun observeTtsAudio(): Flow<ByteArray>
}
```

#### 3.2.3 HybridRecognizer (新增)

```kotlin
/**
 * 混合识别器
 * 职责：智能切换离线/在线识别
 */
class HybridRecognizer(
    private val offlineRecognizer: OfflineRecognizer,
    private val onlineRecognizer: OnlineRecognizer,
    private val connectionService: ConnectionService
) : Recognizer {
    
    // 识别模式
    enum class Mode {
        OFFLINE_ONLY,    // 仅离线
        ONLINE_ONLY,     // 仅在线
        HYBRID_OFFLINE_FIRST,  // 离线优先
        HYBRID_PARALLEL   // 并行识别
    }
    
    private var currentMode = Mode.HYBRID_OFFLINE_FIRST
    
    /**
     * 开始识别
     */
    override suspend fun recognize(audioData: FloatArray): RecognitionResult {
        return when (currentMode) {
            Mode.OFFLINE_ONLY -> offlineRecognizer.recognize(audioData)
            Mode.ONLINE_ONLY -> onlineRecognizer.recognize(audioData)
            Mode.HYBRID_OFFLINE_FIRST -> recognizeHybridOfflineFirst(audioData)
            Mode.HYBRID_PARALLEL -> recognizeParallel(audioData)
        }
    }
    
    /**
     * 离线优先混合模式
     * - 先启动离线识别（快速响应）
     * - 同时启动在线识别（更准确）
     * - 返回离线结果，后台用在线结果修正
     */
    private suspend fun recognizeHybridOfflineFirst(audioData: FloatArray): RecognitionResult
}
```

#### 3.2.4 StateManager (重构)

```kotlin
/**
 * 统一的状态管理器
 * 职责：管理助手的所有状态转换
 */
class StateManager {
    
    /**
     * 助手状态枚举 (参考xiaozhi DeviceState)
     */
    enum class AssistantState {
        UNKNOWN,        // 未知状态
        IDLE,           // 空闲，等待唤醒
        LISTENING,      // 正在监听
        RECOGNIZING,    // 正在识别
        THINKING,       // 正在思考（技能处理）
        SPEAKING,       // 正在说话
        ERROR           // 错误状态
    }
    
    // 当前状态
    private val _currentState = MutableStateFlow(AssistantState.UNKNOWN)
    val currentState: StateFlow<AssistantState> = _currentState.asStateFlow()
    
    // 状态历史
    private val stateHistory = mutableListOf<StateTransition>()
    
    /**
     * 转换到新状态
     */
    fun transitionTo(newState: AssistantState, reason: String = "") {
        val oldState = _currentState.value
        
        // 验证状态转换是否合法
        if (!isValidTransition(oldState, newState)) {
            Log.w(TAG, "Invalid state transition: $oldState -> $newState")
            return
        }
        
        // 记录状态转换
        val transition = StateTransition(
            from = oldState,
            to = newState,
            reason = reason,
            timestamp = System.currentTimeMillis()
        )
        stateHistory.add(transition)
        
        // 更新状态
        _currentState.value = newState
        
        // 触发状态变化事件
        onStateChanged(oldState, newState)
    }
    
    /**
     * 验证状态转换是否合法
     */
    private fun isValidTransition(from: AssistantState, to: AssistantState): Boolean
    
    /**
     * 强制重置到IDLE状态
     */
    fun resetToIdle()
    
    /**
     * 中断当前操作
     */
    fun interrupt(reason: String)
}
```

---

## 四、改动清单

### 4.1 新增类/接口

| 类名 | 包路径 | 说明 |
|-----|--------|-----|
| `AudioService` | `org.stypox.dicio.audio` | 音频服务核心类 |
| `AudioCapture` | `org.stypox.dicio.audio.capture` | 音频采集 |
| `AudioProcessor` | `org.stypox.dicio.audio.processor` | 音频处理(VAD/AEC) |
| `AudioCodec` | `org.stypox.dicio.audio.codec` | 音频编解码 |
| `ConnectionService` | `org.stypox.dicio.connection` | WebSocket连接服务 |
| `WebSocketClient` | `org.stypox.dicio.connection.ws` | WebSocket客户端 |
| `ProtocolHandler` | `org.stypox.dicio.connection.protocol` | 协议处理器 |
| `RecognitionService` | `org.stypox.dicio.recognition` | 识别服务 |
| `HybridRecognizer` | `org.stypox.dicio.recognition.hybrid` | 混合识别器 |
| `OnlineRecognizer` | `org.stypox.dicio.recognition.online` | 在线识别器 |
| `StateManager` | `org.stypox.dicio.state` | 状态管理器 |

### 4.2 重构现有类

| 类名 | 重构内容 | 原因 |
|-----|---------|-----|
| `SttInputDeviceWrapper` | 简化职责，委托AudioService处理音频 | 职责过重 |
| `SenseVoiceInputDevice` | 提取音频处理到AudioService | 逻辑分散 |
| `VoiceAssistantStateProvider` | 简化，使用新的StateManager | 状态管理复杂 |
| `VoiceAssistantStateCoordinator` | 整合到StateManager | 职责重叠 |

### 4.3 保持不变

| 类名 | 说明 |
|-----|-----|
| `EnhancedFloatingWindowService` | 入口服务，保持作为总入口 |
| `WakeDeviceWrapper` | 唤醒词检测，保持不变 |
| `SkillEvaluator` | 技能评估器，保持不变 |
| `SkillHandler`/`SkillRanker` | 技能处理，保持不变 |
| `DraggableFloatingOrb` | 悬浮球UI，保持不变 |

---

## 五、实施计划

### 阶段1：基础服务层 (1-2周)

- [ ] **Task 1.1**: 创建AudioService基础框架
  - 创建`AudioService.kt`
  - 实现`AudioCapture`音频采集
  - 实现基本的音频缓冲管理

- [ ] **Task 1.2**: 实现VAD检测
  - 提取现有VAD逻辑到`AudioProcessor`
  - 集成到AudioService

- [ ] **Task 1.3**: 创建StateManager
  - 定义`AssistantState`枚举
  - 实现状态转换逻辑
  - 实现状态验证

### 阶段2：离线能力重构 (1周)

- [ ] **Task 2.1**: 重构SenseVoiceInputDevice
  - 使用AudioService获取音频
  - 简化职责为纯识别

- [ ] **Task 2.2**: 重构VoskInputDevice
  - 同样使用AudioService
  - 统一接口

- [ ] **Task 2.3**: 集成测试
  - 确保离线模式正常工作
  - 性能对比测试

### 阶段3：在线服务集成 (2-3周)

- [ ] **Task 3.1**: 实现ConnectionService
  - WebSocket客户端封装
  - 协议处理器
  - 重连机制

- [ ] **Task 3.2**: 实现OnlineRecognizer
  - 流式ASR集成
  - 部分识别结果处理

- [ ] **Task 3.3**: 实现OnlineTTS
  - 流式TTS音频接收
  - 实时播放

- [ ] **Task 3.4**: 实现Opus编解码
  - 集成Opus库
  - 编解码器封装

### 阶段4：混合模式 (1-2周)

- [ ] **Task 4.1**: 实现HybridRecognizer
  - 离线优先逻辑
  - 在线修正逻辑

- [ ] **Task 4.2**: 智能切换策略
  - 网络状态检测
  - 自动降级/升级

- [ ] **Task 4.3**: 性能优化
  - 延迟优化
  - 内存优化

### 阶段5：Function Calling (1周)

- [ ] **Task 5.1**: 设计Function Calling协议
  - 定义消息格式
  - 实现调用机制

- [ ] **Task 5.2**: 集成到SkillEvaluator
  - 技能识别后判断是否需要Function Call
  - 执行并返回结果

---

## 六、技术细节

### 6.1 音频格式

- **采样率**: 16000 Hz
- **通道数**: 单声道
- **位深度**: 16-bit PCM → Float32
- **编码格式**: Opus (在线传输)

### 6.2 WebSocket协议

参考xiaozhi-server的协议：

```json
// 发送音频
{
  "type": "audio",
  "format": "opus",
  "sample_rate": 16000,
  "data": "<base64_encoded_opus>"
}

// 接收ASR结果
{
  "type": "asr_result",
  "is_final": false,
  "text": "你好",
  "confidence": 0.95
}

// 接收TTS音频
{
  "type": "tts_audio",
  "format": "opus",
  "data": "<base64_encoded_opus>"
}
```

### 6.3 依赖库

新增依赖：

```kotlin
// OkHttp WebSocket
implementation("com.squareup.okhttp3:okhttp:4.12.0")

// Opus编解码
implementation("com.github.TakuSemba:Opus-Wrapper:1.0.0")
// 或使用sherpa-onnx自带的Opus
```

---

## 七、风险评估

| 风险 | 影响 | 缓解措施 |
|-----|-----|---------|
| 重构导致现有功能不稳定 | 高 | 分阶段实施，保持向后兼容 |
| 在线服务延迟影响体验 | 中 | 离线优先策略，边收边处理 |
| 音频处理性能问题 | 中 | 使用Kotlin Coroutines优化并发 |
| WebSocket连接不稳定 | 中 | 实现自动重连和降级策略 |

---

## 八、后续优化方向

1. **独立为Android Library Module** - 让其他应用可以依赖
2. **AIDL服务化** - 提供跨进程调用能力
3. **多设备同步** - 支持多设备协同
4. **离线Function Calling** - 本地函数调用能力

---

## 九、总结

本次架构优化的核心目标是：

1. ✅ **独立音频服务** - 从InputDevice中解耦
2. ✅ **混合识别模式** - 离线+在线无缝切换
3. ✅ **服务化架构** - 为未来模块化打基础
4. ✅ **精确状态管理** - 清晰的状态机
5. ✅ **边收边处理** - 真正的流式体验

参考xiaozhi-esp32的优秀设计，结合Android平台特性，打造高性能、灵活、可扩展的语音助手架构。

